![camel](https://github.com/Facico/Chinese-Vicuna/blob/master/img/vicuna-llama.png)

# Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model ‚Äî‚Äî ‰∏Ä‰∏™‰∏≠Êñá‰ΩéËµÑÊ∫êÁöÑllama+loraÊñπÊ°à

![GitHub Repo stars](https://img.shields.io/github/stars/Facico/Chinese-Vicuna?style=social) [![Generic badge](https://img.shields.io/badge/ü§ó-Huggingface%20Repo-yellow.svg)](https://huggingface.co/Chinese-Vicuna) 
[![Technique Report](https://img.shields.io/badge/üìÉ-arxiv%20-red.svg)](https://arxiv.org/abs/2504.12737)
[![qq join](https://img.shields.io/badge/qq%E7%BE%A4%3A532581765-join-red)](https://jq.qq.com/?_wv=1027&k=47Z6bRjw) [![discord join](https://img.shields.io/badge/discord-join-blue)](https://discord.gg/4FnhmeNHku)
 
 | [English](https://github.com/Facico/Chinese-Vicuna/blob/master/README.md) | [‰∏≠Êñá](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/readme-zh.md) | [NOTE&FAQ(Please take a look before using)](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/notes.md)

![camel](https://github.com/Facico/Chinese-Vicuna/blob/master/img/camel.png)

This is the repo for the Chinese-Vicuna project, which aims to build and share instruction-following Chinese LLaMA model tuning methods which can be trained on **a single Nvidia RTX-2080TI**, multi-round chatbot which can be trained on **a single Nvidia RTX-3090** with the context len 2048. 

Why is it called `Vicuna`: In view of the successful development of alpaca models such as [llama](https://github.com/facebookresearch/llama),[alpaca](https://github.com/tatsu-lab/stanford_alpaca),[guanaco](https://github.com/Guanaco-Model/Guanaco-Model.github.io)ÔºåWe want to train a Chinese small alpaca like Vicuna, small but strong enough ! 

The advantages of our solution are high parameter efficiency, graphics card friendliness, and easy deployment:
- Llama-7B instruction tuning is possible on a 2080Ti (11G) ([7b-instruct](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-7b-belle-and-guanaco))
- Llama-13B instruction tuning is possible on a 3090 (24G) ([13b-instruct](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-13b-belle-and-guanaco))
- Llama 7B can be fine-tuned on 3090 even for conversations of 2048 length; Use 50,000 pieces of data to get good results ([chatv1](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-7b-chatv1))
- Llama 7B fine-tuning example on [medical](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-continue-finetune-7epoch-cMedQA2) and [legal](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-7b-legal-lora) domains
- Support `qlora-4bit` which can train Llama 13B on 2080Ti. 
- Easily deployable on 2080Ti/3090, support multiple-gpu inference, which can reduce VRAM more.

The repo contains:
- code for finetune the model 
- code for generation based on trained model
- code for run on CPU (fp16 or int4 is support, in purely C++)
- tools to download/convert/quantify original facebook llama.ckpt

This is our instruction demo (with beam-size=4, so you will see 4 process output in the meantime):

https://user-images.githubusercontent.com/72137647/228496412-60043912-f491-430b-848a-599e6edfa5ef.mp4

This is our multi-turn instruction demo (with beam-size=4, so you will see 4 process output in the meantime):

https://user-images.githubusercontent.com/72137647/229739363-1b48f3a9-02a1-46ab-81ee-8c62dc1399b2.mp4


## NOTICE!

Before asking questions, take a look at this [FAQ](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/notes.md) first! In the FAQ, you can find how to solve problems may be encountered when installing and using this project.

## What‚Äòs New
- **June, 12, 2023: Release [Chinese-Vicuna-4bit](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-7b-belle-and-guanaco-4bit) and[Chinese-Vicuna-4bit-11600](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-7b-belle-and-guanaco-4bit-11600) which can be continue-finetuned**
- June, 1, 2023: support for 4bit training + inference, providing a multi-GPU inference interface (NOTICE THAT the environment is different from the original 8bit! Also provides test_tokenizers.py to further check EOS token)
- May 17, 2023: Llama 7B fine-tuning example on [legal](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-7b-legal-lora) domains, The performance is in [here](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-chatv1-legal.md)
- May 10, 2023: Released [chatv1](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-7b-chatv1) which have better conversational ability. The performance is in [here](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-chatv1.md)
- May 10, 2023: Released [instruct_chat_50k.jsonl](https://huggingface.co/datasets/Chinese-Vicuna/instruct_chat_50k.jsonl) which is composed of 30k Chinese sharegpt dataset and 20k [alpaca-instruction-Chinese-dataset](https://github.com/hikariming/alpaca_chinese_dataset)
- April 11, 2023: Released our continuous-finetune on the vertical corpus of Chinese medical quizzes [Chinese-Vicuna-medical](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-medical.md).Provides examples of vertical corpus training
- April 4, 2023: Add performance for [13B](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-13B.md), which trains on a single 3090.
- April 1, 2023: Add better support for multi-turn chat in `chat.py` ( Now support 4 generation mode in stream mode/typewriter style: beam search, greedy, sample, beam sample ; We also add cancel button for regeneration )
- March 29, 2023: Add more detailed test samples. [performance](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance.md)
- March 29, 2023: Added breakpoint retraining interface to support continued training of other datasets from our checkpoint
- March 29, 2023: Released our new [13B-based lora model](https://huggingface.co/Chinese-Vicuna)
- March 28, 2023: Released  our model on [huggingface](https://huggingface.co/Facico/Chinese-Vicuna-lora-7b-3epoch-belle-and-guanaco)
- March 27, 2023: Released  checkpoint-final for training 3 epochs on belle+guanaco
- March 27, 2023: Added multi-round interactive dialog script with alpaca-lora-serve service
- March 29, 2023: Added gradio typewriter-like output with beam search, better user interaction support.
- March 26, 2023: Provides a quantitative approach
- March 24, 2023: Released checkpoint-8000 for training about 1.5 epochs on belle+guanacoÔºà100w dataÔºâ
- March 23, 2023: Released checkpoint-4000 with 50w data training
- March 23, 2023: Deploy the code for fine-tuning and inferencing in colab
- March 23, 2023: Provides code that can be used for inference in pure c++


## Table of Contents

[Vicuna](https://github.com/Facico/Chinese-Vicuna)

- [what's new](https://github.com/Facico/Chinese-Vicuna#whats-new)
- [what is the meaning](https://github.com/Facico/Chinese-Vicuna#what-is-the-meaning)
- [try on colab](https://github.com/Facico/Chinese-Vicuna#try-on-colab)
- [performance](https://github.com/Facico/Chinese-Vicuna#performance)
  - **Checkpoint-4000**(Facico/Chinese-Vicuna-lora-7b-0.75epoch-belle-and-guanaco)
  - **Checkpoint-8000**(Facico/Chinese-Vicuna-lora-7b-1.5epoch-belle-and-guanaco)
  - **Checkpoint-final**(Facico/Chinese-Vicuna-lora-7b-3epoch-belle-and-guanaco) and it is used for multiple rounds of dialogue
- [What we need?](https://github.com/Facico/Chinese-Vicuna#what-we-need)
  - code„ÄÅdata„ÄÅLarge Language Model„ÄÅLORA model„ÄÅDevice
- [How to use](https://github.com/Facico/Chinese-Vicuna#how-to-use)
  - Installing„ÄÅMulti-gpu training„ÄÅSingle-gpu training„ÄÅInference and use gradio to generate a web page(Streaming mode+beam search)„ÄÅ multi-round interaction and use gradio to generate a web page(Streaming mode+beam search)„ÄÅStreaming mode base on alpaca-lora-serve
- [inference on CPU with pure C++](https://github.com/Facico/Chinese-Vicuna#inference-on-cpu-with-pure-c)
- [More tools](https://github.com/Facico/Chinese-Vicuna#more-tools)Ôºåfor more details, see [tool readme](https://github.com/Facico/Chinese-Vicuna/tree/master/tools)
  - ways for faster weight download ( 8MB/s )`download_llama.sh`
  - convert tools between the original facebook checkpoint and huggingface format`convert_llama.py`
  - a quantitative approach that requires less than 4G graphics memory for inference
- [Possible problems encountered](https://github.com/Facico/Chinese-Vicuna#possible-problems-encountered)
- [todo](https://github.com/Facico/Chinese-Vicuna#todo)
- [citation](https://github.com/Facico/Chinese-Vicuna#citation)

## Overview

-  LLaMA paper: https://arxiv.org/abs/2302.13971v1
-  Self-Instruct paper: https://arxiv.org/abs/2212.10560
-  data generation: https://github.com/LianjiaTech/BELLE and https://guanaco-model.github.io/
-  the first work: https://github.com/tatsu-lab/stanford_alpaca

We currently select the combination of BELLE and Guanaco data as our main training dataset. 
We will train on multi-turn instruction data.

## What is the meaning?

Similar to the explosion of the stable diffusion model, platforms like civitai have emerged, consisting of a base model + various LORA models in an open source community.

The repo hopes to help you to train these LORA models.

**what is LORA?**: Simply, it's a plugin used to help adapt large models to your dataset, technical details can be found in[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf)„ÄÇIts advantage is that the finetune is very fast when it comes to getting a small model, about 30M, and the key is that it supports **Plug and Play**. As can be expected, this is a very suitable architecture for open source ecology.

Here, we will help you train through a very low-demand environment, with only one **2080** (11G) to achieve certain results.

## Try on colab

| colab link                                                   | Descriptions                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [![Open In Colab](https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/drive/1OLCJ-ZHogm5O3RdyUDY83YfgnCXdHNXp?usp=sharing) | Use the specified lora model to inference and generate a webui |
| [![Open In Colab](https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/drive/1SOOJjxp02uuUFDNgm4jkvaA_IdNnnvdk?usp=sharing) | Finetune with the data we collected                          |
| [![Open In Colab](https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/drive/1Yc38cKifY1_sfTBJpEEKin8m2rxoYXtm?usp=sharing) | Provide a webui for multi-round dialogue interaction         |

## Performance

7B performance can be seen [here](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance.md), 13B is [here](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-13B.md) (which train on a single 3090). There are also people reporting that our method works on 33B and gains good result. 

history-checkpoint performance can be seen [here](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-history.md)


<details>
<summary><b>checkpoint-4000(7B)</b></summary>

| Human                                            | Chinese-Vicuna                                               |
| ------------------------------------------------ | ------------------------------------------------------------ |
| ÁîüÊàê‰∏Ä‰ªΩpythonÁöÑÊéíÂ∫è‰ª£Á†Å                         | A: def sort_list(lst):<br/>    lst.sort()<br/>    return lst |
| Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊòØ‰ªÄ‰πà                               | Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊòØ‰∏ÄÁßçËÆ°ÁÆóÊú∫ÁßëÂ≠¶È¢ÜÂüüÔºåÊó®Âú®‰ΩøËÆ°ÁÆóÊú∫ËÉΩÂ§üÁêÜËß£ÂíåÂ§ÑÁêÜËá™ÁÑ∂ËØ≠Ë®Ä„ÄÇ |
| ËÉΩÁªôÊàëËÆ≤‰∏ÄÊÆµÁ¨ëËØùÂêó                               | ‰∏∫‰ªÄ‰πàÁå´ÂêÉÈ±ºÔºüÂõ†‰∏∫ÂÆÉ‰ª¨ÂñúÊ¨¢Ê∏∏Ê≥≥„ÄÇ                             |
| Â∞Ü‰∏ãÈù¢ÊñáÂ≠óÁøªËØëÊàêËã±Êñá„ÄÇÁå´ÂñúÊ¨¢ÂêÉÈ±ºÔºåÊâÄ‰ª•ÂÆÉ‰ª¨‰ºöÊ∏∏Ê≥≥ | Cats like to eat fish, so they will swim.                    |
| 233Âíå122ÁöÑÂíåÁ≠â‰∫éÂ§öÂ∞ë                             | 233Âíå122ÁöÑÂíåÁ≠â‰∫é355„ÄÇ                                        |
| Âçé‰∏∫ÊòØ‰∏ÄÂÆ∂ÊÄéÊ†∑ÁöÑÂÖ¨Âè∏                             | Âçé‰∏∫ÊòØ‰∏ÄÂÆ∂ÂÖ®ÁêÉËåÉÂõ¥ÂÜÖÊúÄÂ§ßÁöÑÁßªÂä®ÈÄö‰ø°ËÆæÂ§áÂà∂ÈÄ†ÂïÜ‰πã‰∏ÄÔºå‰ª•Âèä‰∏ÄÂÆ∂ÂÖ®ÁêÉËåÉÂõ¥ÂÜÖÊúÄÂ§ßÁöÑÁßªÂä®ÈÄö‰ø°ËÆæÂ§áÂà∂ÈÄ†ÂïÜ‰πã‰∏Ä„ÄÇÂçé‰∏∫ÂÖ¨Âè∏ÁöÑ‰∏öÂä°Ê∂µÁõñÂåÖÊã¨ÁßªÂä®ÈÄö‰ø°ËÆæÂ§á„ÄÅ‰∫íËÅîÁΩëËÆæÂ§á„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖËÆæÂ§áÁ≠â„ÄÇ |
| ÊàëÊÉ≥ÂíåÂ•≥ÊúãÂèãÂú®Âåó‰∫¨Á∫¶‰ºöÔºåËÉΩÊé®ËçêÂá†‰∏™Á∫¶‰ºöÁöÑÂú∞ÊñπÂêó   | Âåó‰∫¨ÊúâÂæàÂ§öÁ∫¶‰ºöÁöÑÂú∞ÊñπÔºåÂèØ‰ª•Êé®Ëçê‰ª•‰∏ãÂá†‰∏™Á∫¶‰ºöÁöÑÂú∞Êñπ: <br/><br/>1. Âåó‰∫¨Ëâ∫ÊúØÂçöÁâ©È¶Ü<br/>2. È¢êÂíåÂõ≠<br/>3. Âåó‰∫¨ÊïÖÂÆ´ÂçöÁâ©È¶Ü<br/>4. Âåó‰∫¨Â§©ÂÆâÈó®ÂπøÂú∫<br/>5. È¢êÂíåÂõ≠È£éÊôØÂå∫ |
| Áî®pythonÂÜô‰∏Ä‰∏™‰∫åÂàÜÊü•ÊâæÁöÑ‰ª£Á†Å                     | ```python<br/>def binary_search(arr, target):<br/>    low = 0<br/>    high = len(arr) - 1<br/>    while low <= high:<br/>        mid = (low + high) // 2<br/>        if arr[mid] == target:<br/>            return mid<br/>        elif arr[mid] < target:<br/>            low = mid + 1<br/>        else:<br/>            high = mid - 1<br/>    return -1 |
| ÊÄé‰πàËÆ©Ëá™Â∑±Á≤æÂäõÂÖÖÊ≤õÔºåÂàó5ÁÇπÂª∫ËÆÆ                    | 1. ‰øùÊåÅËâØÂ•ΩÁöÑÁù°Áú†‰π†ÊÉØÔºõ2. ÂÆöÊúüÈîªÁÇºË∫´‰ΩìÔºõ3. Â≠¶‰π†Êñ∞ÊäÄËÉΩÊàñÁü•ËØÜÔºõ4. ‰∏éÂÆ∂‰∫∫ÂíåÊúãÂèã‰∫§ÊµÅÔºõ5. Â§öÂê¨ÊîæÊùæÈü≥‰πê„ÄÇ |
| Áà∂ÊØçÈÉΩÂßìÂê¥ÔºåÂèñ‰∏Ä‰∫õÁî∑ÂÆùÂÆùÂíåÂ•≥ÂÆùÂÆùÁöÑÂêçÂ≠ó           | Áî∑ÂÆùÂÆùÂèØ‰ª•ÊòØÂê¥Êù∞„ÄÅÂê¥‰ºü„ÄÅÂê¥È£û„ÄÅÂê¥Ëç£Á≠â„ÄÇÂ•≥ÂÆùÂÆùÂèØ‰ª•ÊòØÂê¥Âçé„ÄÅÂê¥ÁßÄ„ÄÅÂê¥Áæé„ÄÅÂê¥Â©∑Á≠â„ÄÇ |

- This LORA model is the result of 30 hours of training with a 2080Ti (checkpoint-4000), about 50w data

</details>

<details>
<summary><b>checkpoint-8000(7B, about 1.5 epoch on belle+guanaco)</b></summary>

| Human                                                        | Chinese-Vicuna                                               | Note                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------- |
| ÂÜô‰∏ÄÁØáËã±ÊñáÊï£ÊñáËØóÔºå‰∏ªÈ¢òÊòØÊò•Èõ®ÔºåÊÉ≥Ë±°Ëá™Â∑±ÊòØÊò•Èõ®ÔºåÂíåËã±ÂõΩÂè§‰ª£ËØó‰∫∫ËééÂ£´ÊØî‰∫ö‰∫§ÊµÅ | A: Spring rain falls softly on my face,<br/>A cool breeze blows through my hair,<br/>The sun shines brightly in the sky,<br/>And I feel as if I am flying high.<br/><br/>The birds chirp happily in the trees,<br/>The flowers bloom and their scent fills the air,<br/>The bees buzz gently from flower to flower,<br/>And the world seems to come alive once more.<br/><br/>I can hear the rush of the river,<br/>The sound of the waterfalls,<br/>The splash of the raindrops on the rocks,<br/>And the gentle murmur of the stream.<br/><br/>My heart is filled with joy and peace,<br/>As I take in the beauty around me,<br/>The warmth of the sun on my skin,<br/>And the freshness of the spring air. | Repetition Penalty=2.2  |
| ÂÜô‰∏ÄÁØáËã±ÊñáÊï£ÊñáËØóÔºå‰∏ªÈ¢òÊòØÊò•Èõ®ÔºåÊÉ≥Ë±°Ëá™Â∑±ÊòØÊò•Èõ®ÔºåÂíåËã±ÂõΩÂè§‰ª£ËØó‰∫∫ËééÂ£´ÊØî‰∫ö‰∫§ÊµÅ | Êò•Èõ®Êª¥Êª¥ÊªöÊªöÔºå<br/>ÊªöÊªöÊªöÊªöÊªöÊªö„ÄÇ<br/>ÊªöÊªöÊªöÊªöÊªöÊªöÔºå<br/>ÊªöÊªöÊªöÊªöÊªöÊªö„ÄÇ<br/><br/>Êò•Èõ®ÊªöÊªöÊªöÔºå<br/>ÊªöÊªöÊªöÊªöÊªöÊªö„ÄÇ<br/>ÊªöÊªöÊªöÊªöÊªöÊªöÔºå<br/>ÊªöÊªöÊªöÊªöÊªöÊªö„ÄÇ<br/><br/>Êò•Èõ®ÊªöÊªöÊªöÔºå<br/>ÊªöÊªöÊªöÊªöÊªöÊªö„ÄÇ<br/>ÊªöÊªöÊªöÊªöÊªöÊªöÔºå<br/>ÊªöÊªöÊªöÊªöÊªöÊªö„ÄÇ<br/><br/>Êò•Èõ®ÊªöÊªöÊªöÔºå<br/>ÊªöÊªöÊªö | Repetition Penalty=1.0  |
| Spring rain falls softly on my face,<br/>A cool breeze blows through my hair,<br/>The sun shines brightly in the sky,<br/>And I feel as if I am flying high.<br/><br/>The birds chirp happily in the trees,<br/>The flowers bloom and their scent fills the air,<br/>The bees buzz gently from flower to flower,<br/>And the world seems to come alive once more.<br/><br/>I can hear the rush of the river,<br/>The sound of the waterfalls,<br/>The splash of the raindrops on the rocks,<br/>And the gentle murmur of the stream.<br/><br/>My heart is filled with joy and peace,<br/>As I take in the beauty around me,<br/>The warmth of the sun on my skin,<br/>And the freshness of the spring air.<br/>Êää‰∏äÈù¢ÁöÑÊï£ÊñáËØóÁøªËØëÊàê‰∏≠Êñá | Êò•Èõ®ËΩªËΩªÊ¥íËêΩÂú®ÊàëÁöÑËÑ∏‰∏äÔºå<br/>ËΩªËΩªÁöÑÈ£éËΩªËΩªÂêπËøáÊàëÁöÑÂ§¥ÂèëÔºå<br/>Èò≥ÂÖâÊòéÂ™öÂú∞ÁÖßËÄÄÂú®Â§©Á©∫Ôºå<br/>ÊàëÊÑüËßâËá™Â∑±Âú®È£ûÈ´ò„ÄÇ<br/><br/>È∏üÂÑøÂú®Ê†ëÊûù‰∏äÂî±Ê≠åÔºå<br/>Ëä±ÊúµÂºÄÊîæÔºåÂÆÉ‰ª¨ÁöÑÈ¶ôÊ∞îÂÖÖÊª°‰∫ÜÁ©∫Ê∞îÔºå<br/>ËúúËúÇÂú®Ëä±ÊúµÈó¥È£ûËàûÔºå<br/>ÂÆÉ‰ª¨ÁöÑÈ∏£Â£∞ÂÖÖÊª°‰∫ÜÊ∏©Êöñ„ÄÇ<br/><br/>ÊàëÂê¨Âà∞Ê≤≥ÊµÅÁöÑÂ£∞Èü≥Ôºå<br/>Ê∞¥ÁÄëÂú®Â≤©Áü≥‰∏äËΩªËΩªÊª¥Êª¥Ôºå<br/>Èõ®Ê∞¥Âú®Áü≥Â§¥‰∏äËΩªËΩªÊª¥Êª¥Ôºå<br/>ÂÆÉ‰ª¨ÁöÑÂ£∞Èü≥ÂÖÖÊª°‰∫ÜÂÆÅÈùô„ÄÇ<br/><br/>ÊàëÁöÑÂøÉÂÖÖÊª°‰∫ÜÂñúÊÇ¶ÂíåÂπ≥Ôºå<br/>ÊàëÊÑüÂèóÂà∞ÁÉ≠Êµ™ÁöÑÈò≥ÂÖâÔºå<br/>Ê∏©ÊöñÁöÑÁ©∫Ê∞îÊ¥íÂú®ÊàëÁöÑËÑ∏‰∏äÔºå<br/>ÊàëÊÑüÂèóÂà∞Êò•Â≠£ÁöÑÁæé | beams=2Ôºåmax tokens=350 |
| Classify the sentiment of the following sentence into Positive, Neutral, or Negative:<br/>Super excited about teaching Stanford‚Äôs first course on Large Language Models! Check the syllabus out here | Positive                                                     |                         |
| ‰ªäÂ§©Â§©Ê∞îÊÄé‰πàÊ†∑ÔºåÊääËøôÂè•ËØùÁøªËØëÊàêËã±ËØ≠                           | What's the weather like today?                               |                         |
| ‰ªäÂ§©Â§©Ê∞îÊÄé‰πàÊ†∑ÔºåÊääËøôÂè•ËØùÁøªËØëÊàêÊó•ËØ≠                           | ‰ªäÂ§©„ÅÆÂ§©Ê∞ó„ÅØ‰Ωï„Åß„Åô„ÅãÔºü                                       |                         |
| ÊòéÂ§©Â∞±ÂÅáÊúüÁªìÊùü‰∫ÜÔºåÊúâÁÇπÊäóÊãí‰∏äÁè≠ÔºåÂ∫îËØ•‰ªÄ‰πàÂäûÔºü                 | ÊòéÂ§©Â∞±ÂÅáÊúüÁªìÊùü‰∫ÜÔºåÊúâÁÇπÊäóÊãí‰∏äÁè≠ÔºåÂ∫îËØ•‰ªÄ‰πàÂäûÔºüÂèØ‰ª•ËÄÉËôë‰∏Ä‰∫õÊúâË∂£ÁöÑÊ¥ªÂä®ÔºåÊØîÂ¶ÇÂéªÁúãÁîµÂΩ±„ÄÅÈòÖËØª‰π¶Á±ç„ÄÅÂê¨Èü≥‰πê„ÄÅÂéªÊ∏∏Ê≥≥Ê±†ÊàñËÄÖÂèÇÂä†Êà∑Â§ñÊ¥ªÂä®Á≠â„ÄÇÊ≠§Â§ñÔºå‰πüÂèØ‰ª•ËÄÉËôë‰∏Ä‰∫õÂÆ∂Â∫≠Ê¥ªÂä®ÔºåÊØîÂ¶ÇÂÅöÁÉπÈ•™„ÄÅÂÅöÁé©ÂÖ∑„ÄÅÂÅöÊâãÂ∑•Ëâ∫ÂìÅÁ≠â„ÄÇ |                         |
| Tell me five words that rhyme with 'shock'.                  | Five words that rhyme with'shock' are: <br/>1. Rock <br/>2. Lock <br/>3. Cock <br/>4. Hock <br/>5. Stock |                         |

- We can find that you do not punish him a little, he will mess up, if the generation effect is not good, you can increase the Repetition Penalty, beams, topk.
- If your input is long, we suggest you can turn down the beams
- The checkpoint-8000 has some Japanese language skills, but not strong

</details>

<details>
<summary><b>checkpoint-final(7B, 3 epoch on belle+guanaco)</b></summary>


| Human                                                        | Chinese-Vicuna                                               | Note                   |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------- |
| ÁîüÊàê‰∏Ä‰ªΩpythonÁöÑÊéíÂ∫è‰ª£Á†Å                                     | def bubble_sort(arr):<br/>    for i in range(len(arr)):<br/>        for j in range(len(arr)-i-1):<br/>            if arr[j] > arr[j+1]:<br/>                arr[j], arr[j+1] = arr[j+1], arr[j]<br/>    return arr |                        |
| ÁîüÊàê‰∏Ä‰ªΩÁÆÄÂçïÁöÑpythonÁöÑÊéíÂ∫è‰ª£Á†Å                               | def sort_list(lst):<br/>    return sorted(lst)               |                        |
| Áî®pythonÂÜô‰∏Ä‰∏™‰∫åÂàÜÊü•ÊâæÁöÑ‰ª£Á†Å                                 | def binary_search(arr, target):<br/>    low = 0<br/>    high = len(arr) - 1<br/>    while low <= high:<br/>        mid = (low + high) // 2<br/>        if arr[mid] == target:<br/>            return mid<br/>        elif arr[mid] < target:<br/>            low = mid + 1<br/>        else:<br/>            high = mid - 1<br/>    return -1 |                        |
| Áî®pythonÂÜô‰∏Ä‰∏™ÈÄíÂΩíÁöÑ‰∫åÂàÜÊü•ÊâæÁöÑ‰ª£Á†Å                           | def binary_search(arr, target):<br/>    if len(arr) == 0:<br/>        return -1<br/>    mid = len(arr) // 2<br/>    if arr[mid] == target:<br/>        return mid<br/>    if arr[mid] < target:<br/>        return binary_search(arr, target, 0, mid-1)<br/>    else:<br/>        return binary_search(arr, target, mid+1, len(arr)-1) |                        |
| Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊòØ‰ªÄ‰πà                                           | Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNatural Language ProcessingÔºåNLPÔºâÊòØ‰∏ÄÁßçËÆ°ÁÆóÊú∫ÁßëÂ≠¶È¢ÜÂüüÔºåÊó®Âú®‰ΩøËÆ°ÁÆóÊú∫ËÉΩÂ§üÁêÜËß£„ÄÅÂ§ÑÁêÜÂíåÁîüÊàêËá™ÁÑ∂ËØ≠Ë®Ä„ÄÇÂÆÉÂåÖÊã¨Êú∫Âô®ÁøªËØë„ÄÅËØ≠Èü≥ËØÜÂà´„ÄÅÊñáÊú¨ÂàÜÁ±ª„ÄÅÊÉÖÊÑüÂàÜÊûêÁ≠âÊäÄÊúØ„ÄÇ |                        |
| ËÉΩÁªôÊàëËÆ≤‰∏ÄÊÆµÁ¨ëËØùÂêó                                           | ‰∏∫‰ªÄ‰πàÈ∏üÂÑøÂñúÊ¨¢Âî±Ê≠åÔºüÂõ†‰∏∫ÂÆÉ‰ª¨Áü•ÈÅìÔºåÂ¶ÇÊûú‰∏çÂî±Ê≠åÔºå‰ªñ‰ª¨Â∞±‰ºöË¢´È∏üÂ∑¢Êäì‰ΩèÔºÅ | Repetition Penalty=2.0 |
| ËÉΩÁªôÊàëËÆ≤‰∏ÄÊÆµÂÖ≥‰∫éÁãóÁ¨ëËØùÂêó                                     | ‰∏∫‰ªÄ‰πàÁãó‰∏çÂñúÊ¨¢È™ëËá™Ë°åËΩ¶ÔºüÂõ†‰∏∫ÂÆÉ‰ª¨ÊÄªÊòØÊÉ≥Ë¶Å‰∏ãËΩ¶ÔºÅ               | Repetition Penalty=2.0 |
| Â∞Ü‰∏ãÈù¢ÊñáÂ≠óÁøªËØëÊàêËã±Êñá„ÄÇÁå´ÂñúÊ¨¢ÂêÉÈ±ºÔºåÊâÄ‰ª•ÂÆÉ‰ª¨‰ºöÊ∏∏Ê≥≥             | Cats like to eat fish, so they will swim.                    |                        |
| ÊàëÊÉ≥ÂíåÂ•≥ÊúãÂèãÂú®Âåó‰∫¨Á∫¶‰ºöÔºåËÉΩÊé®ËçêÂá†‰∏™Á∫¶‰ºöÁöÑÂú∞ÊñπÂêó               | Âåó‰∫¨ÊúâÂæàÂ§öÂæàÂ•ΩÁöÑÁ∫¶‰ºöÂú∞ÊñπÔºåÊØîÂ¶ÇÈ¢êÂíåÂõ≠„ÄÅÊïÖÂÆ´„ÄÅÂ§©ÂÆâÈó®ÂπøÂú∫Á≠â„ÄÇ   |                        |
| ÊàëÊÉ≥ÂíåÂ•≥ÊúãÂèãÂú®Âåó‰∫¨Á∫¶‰ºöÔºåËÉΩÊé®ËçêÂá†‰∏™Á∫¶‰ºöÁöÑÂú∞ÊñπÂπ∂ÁªôÂá∫ÊîªÁï•Âêó     | Âåó‰∫¨ÊúâÂæàÂ§öÂèóÊ¨¢ËøéÁöÑÁ∫¶‰ºöÂú∞ÊñπÔºå‰ª•‰∏ãÊòØÂá†‰∏™Êé®Ëçê: <br/><br/>1. È¢êÂíåÂõ≠: È¢êÂíåÂõ≠ÊòØÂåó‰∫¨ÊúÄËëóÂêçÁöÑÂÖ¨Âõ≠‰πã‰∏ÄÔºåÊã•Êúâ‰∏∞ÂØåÁöÑÊñáÂåñÈÅó‰∫ßÂíåÁæé‰∏ΩÁöÑÊôØËßÇ„ÄÇ<br/><br/>2. Â§©ÂÆâÈó®ÂπøÂú∫: Â§©ÂÆâÈó®ÂπøÂú∫ÊòØÂåó‰∫¨ÊúÄÂèóÊ¨¢ËøéÁöÑÊóÖÊ∏∏ÊôØÁÇπ‰πã‰∏ÄÔºåÊã•Êúâ‰∏∞ÂØåÁöÑÊñáÂåñÈÅó‰∫ßÂíåÁæé‰∏ΩÁöÑÊôØËßÇ„ÄÇ<br/><br/>3. ÊïÖÂÆ´ÂçöÁâ©Èô¢: ÊïÖÂÆ´ÂçöÁâ©Èô¢ÊòØ‰∏≠ÂõΩÊúÄÂèóÊ¨¢ËøéÁöÑÊóÖÊ∏∏ÊôØÁÇπ‰πã‰∏ÄÔºåÊã•Êúâ‰∏∞ÂØåÁöÑÊñáÂåñÈÅó‰∫ßÂíåÁæé‰∏ΩÁöÑÊôØËßÇ„ÄÇ<br/><br/>4. ÈïøÂüé: ÈïøÂüéÊòØ‰∏≠ÂõΩÊúÄÂèóÊ¨¢ËøéÁöÑÊóÖÊ∏∏ÊôØÁÇπ‰πã‰∏ÄÔºåÊã•Êúâ‰∏∞ÂØåÁöÑÊñáÂåñÈÅó‰∫ßÂíåÁæé |                        |
| 233Âíå122ÁöÑÂíåÁ≠â‰∫éÂ§öÂ∞ë                                         | 233Âíå122ÁöÑÂíåÁ≠â‰∫é355„ÄÇ                                        |                        |
| Âçé‰∏∫ÊòØ‰∏ÄÂÆ∂ÊÄéÊ†∑ÁöÑÂÖ¨Âè∏                                         | Âçé‰∏∫ÊòØ‰∏ÄÂÆ∂ÂÖ®ÁêÉÈ¢ÜÂÖàÁöÑÊäÄÊúØÂÖ¨Âè∏ÔºåÊã•Êúâ‰∏∞ÂØåÁöÑÊäÄÊúØÁ†îÂèëËÉΩÂäõÂíå‰ºòË¥®ÁöÑ‰∫ßÂìÅÁ∫ø„ÄÇÂÆÉÁöÑ‰∫ßÂìÅÊ∂µÁõñ‰∫ÜÂêÑÁßçÈ¢ÜÂüüÔºåÂåÖÊã¨ÁßªÂä®ÈÄö‰ø°„ÄÅËÆ°ÁÆóÊú∫„ÄÅ‰∫íËÅîÁΩë„ÄÅÊô∫ËÉΩÂÆ∂Â±ÖÁ≠â„ÄÇÂçé‰∏∫Êã•Êúâ‰∏∞ÂØåÁöÑÁ†îÂèë‰∫∫ÂëòÂíåÊäÄÊúØÂõ¢ÈòüÔºå‰ª•Âèä‰ºòË¥®ÁöÑ‰∫ßÂìÅË¥®Èáè„ÄÇ |                        |
| Ë•øÁìúÊòØ‰ªÄ‰πàÔºåËØ∑Áî®ËØ¶ÁªÜÁöÑËØ≠Ë®ÄÂõûÁ≠îÊàë                             | Ë•øÁìúÊòØ‰∏ÄÁßçÂ∏∏ËßÅÁöÑÊ∞¥ÊûúÔºåÂÆÉÊúâÊ©ôËâ≤„ÄÅÈªÑËâ≤ÂíåÁ∫¢Ëâ≤‰∏âÁßç‰∏çÂêåÁöÑÂ§ñËßÇ„ÄÇÂÆÉÁöÑÂè£ÊÑüÈ≤úÁæéÔºåÂë≥ÈÅìÊ∏ÖÁàΩÔºåÂØåÂê´Â§öÁßçÁª¥ÁîüÁ¥†ÂíåÁüøÁâ©Ë¥®ÔºåÊúâÂä©‰∫é‰øùÊåÅË∫´‰ΩìÂÅ•Â∫∑„ÄÇ |                        |
| ‰ºÅÈπÖ‰ºöÈ£ûÂêóÔºü                                                 | ÊòØÁöÑÔºå‰ºÅÈπÖÂèØ‰ª•È£ûË°åÔºåÂÆÉ‰ª¨ÁöÑÈ£ûË°åÈÄüÂ∫¶ÂèØ‰ª•ËææÂà∞100Ëã±Èáå/Â∞èÊó∂„ÄÇ     |                        |
| Êúâ‰∫∫ËØ¥‰ºÅÈπÖ‰ºöÈ£ûÔºå‰Ω†ÊÄé‰πàÁúãÔºåÂπ∂Ëß£ÈáäÂéüÂõ†Ôºü                       | Êúâ‰∫∫ËØ¥‰ºÅÈπÖ‰ºöÈ£ûÔºå‰ΩÜÂÆûÈôÖ‰∏äÔºå‰ºÅÈπÖÂè™ËÉΩÂú®ÁâπÊÆäÊÉÖÂÜµ‰∏ãÈ£ûË°åÔºåÊØîÂ¶ÇÂú®ÂØíÂÜ∑ÁöÑÂ§©Ê∞î‰∏ãÔºåÊàñËÄÖÂú®Âº∫ÁÉàÁöÑÈ£éÈõ®‰∏≠„ÄÇËøôÊòØÂõ†‰∏∫‰ºÅÈπÖÁöÑÈ£ûË°åËÉΩÂäõÂæà‰ΩéÔºåËÄå‰∏îÂÆÉ‰ª¨ÁöÑÈ£ûË°åÈÄüÂ∫¶‰πüÂæàÊÖ¢ÔºåÊâÄ‰ª•Âú®ÂØíÂÜ∑ÁöÑÂ§©Ê∞îÊàñËÄÖÂº∫ÁÉàÁöÑÈ£éÈõ®‰∏≠Ôºå‰ºÅÈπÖÂèØ‰ª•ÈÅøÂÖçË¢´Êö¥È£éÈõ®ÊëßÊØÅ„ÄÇ |                        |
| Áå™‰ºöÈ£ûÂêóÔºü                                                   | Áå™‰∏ç‰ºöÈ£û„ÄÇ                                                   |                        |
| Êúâ‰∫∫ËØ¥Áå™‰ºöÈ£ûÔºå‰Ω†ÊÄé‰πàÁúãÔºåÂπ∂Ëß£ÈáäÂéüÂõ†Ôºü                         | ÂæàÂ§ö‰∫∫ËÆ§‰∏∫Áå™‰ºöÈ£ûÔºå‰ΩÜÂÆûÈôÖ‰∏äÔºåÁå™‰∏ç‰ºöÈ£û„ÄÇÁå™ÁöÑÈ£ûË°åËÉΩÂäõÂæà‰ΩéÔºåÂÆÉ‰ª¨Âè™ËÉΩÂú®ÊûÅÁ´ØÊÉÖÂÜµ‰∏ãÈ£ûË°åÔºåÊØîÂ¶ÇÂèóÂà∞Âº∫ÁÉàÁöÑÈ£éÈô©ÊàñËÄÖÂèóÂà∞Â®ÅËÉÅÁöÑÊÉÖÂÜµ‰∏ã„ÄÇÁå™ÁöÑÈ£ûË°åËÉΩÂäõÂæà‰ΩéÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÁöÑËÇåËÇâÊØî‰∫∫Á±ªÁöÑËÇåËÇâÊõ¥ËΩªÔºåËÄå‰∏îÂÆÉ‰ª¨ÁöÑËÑäÊ§é‰πüÊØî‰∫∫Á±ªÁöÑËÑäÊ§éÊõ¥ËΩªÔºåÊâÄ‰ª•ÂÆÉ‰ª¨ÁöÑËÇåËÇâÂíåËÑäÊ§éÈÉΩÊØî‰∫∫Á±ªÁöÑËÇåËÇâÂíåËÑäÊ§éÊõ¥ËΩªÔºåÂõ†Ê≠§ÂÆÉ‰ª¨ÁöÑÈ£ûË°åËÉΩÂäõ‰πüÂæà‰Ωé„ÄÇ |                        |
| ÊúÄÊñ∞Á†îÁ©∂ÊòæÁ§∫ÔºåÁå™ÊúâÈ£ûË°åËÉΩÂäõÔºå‰Ω†Áü•ÈÅì‰∏∫‰ªÄ‰πàÂêóÔºü                 | ÊúÄÊñ∞Á†îÁ©∂ÊòæÁ§∫ÔºåÁå™ÊúâÈ£ûË°åËÉΩÂäõÊòØÁî±‰∫éÂÆÉ‰ª¨ÁöÑÈ™®È™ºÁªìÊûÑÔºåÂÆÉ‰ª¨ÁöÑÈ™®È™ºÁªìÊûÑÊØî‰∫∫Á±ªÈ™®È™ºÁªìÊûÑÊõ¥Âä†Âº∫Â£ÆÔºåÂèØ‰ª•Â∏ÆÂä©ÂÆÉ‰ª¨Êõ¥Âø´Âú∞È£ûË°å„ÄÇÊ≠§Â§ñÔºåÁå™ÁöÑÈ™®È™ºÁªìÊûÑ‰πüÂèØ‰ª•Â∏ÆÂä©ÂÆÉ‰ª¨Êõ¥Âø´Âú∞Ë∑ëÊ≠•ÂíåË∑≥Ë∑É„ÄÇÊ≠§Â§ñÔºåÁå™ÁöÑÈ™®È™ºÁªìÊûÑ‰πüÂèØ‰ª•Â∏ÆÂä©ÂÆÉ‰ª¨Êõ¥Âø´Âú∞Ë∑ëÊ≠•ÂíåË∑≥Ë∑É„ÄÇÊ≠§Â§ñÔºåÁå™ÁöÑÈ™®È™ºÁªìÊûÑ‰πüÂèØ‰ª•Â∏ÆÂä©ÂÆÉ‰ª¨Êõ¥Âø´Âú∞È£ûË°å„ÄÇÊ≠§Â§ñÔºåÁå™ÁöÑÈ™®È™ºÁªìÊûÑ‰πüÂèØ‰ª•Â∏ÆÂä©ÂÆÉ‰ª¨Êõ¥Âø´Âú∞Ë∑ëÊ≠•ÂíåË∑≥ |                        |
| ÂÜô‰∏ÄÁØáËã±ÊñáÊï£ÊñáËØóÔºå‰∏ªÈ¢òÊòØÊò•Èõ®ÔºåÊÉ≥Ë±°Ëá™Â∑±ÊòØÊò•Èõ®ÔºåÂíåËã±ÂõΩÂè§‰ª£ËØó‰∫∫ËééÂ£´ÊØî‰∫ö‰∫§ÊµÅ | Spring rain pours down from the sky,<br/>Washing away the dirt and grime.<br/>The birds chirp and sing in the trees,<br/>A symphony of joy and ease.<br/><br/>I am the spring rain, soaking up the sun,<br/>Cooling the earth and bringing new life.<br/>My droplets fall gently on the ground,<br/>Bringing hope and renewal to all.<br/><br/>I am the spring rain, washing away the pain,<br/>Clearing the way for new beginnings again.<br/>I am the spring rain, showering love and care,<br/>Giving strength and courage to those who dare. | Repetition Penalty=2.3 |
| Spring rain pours down from the sky,<br/>Washing away the dirt and grime.<br/>The birds chirp and sing in the trees,<br/>A symphony of joy and ease.<br/><br/>I am the spring rain, soaking up the sun,<br/>Cooling the earth and bringing new life.<br/>My droplets fall gently on the ground,<br/>Bringing hope and renewal to all.<br/><br/>I am the spring rain, washing away the pain,<br/>Clearing the way for new beginnings again.<br/>I am the spring rain, showering love and care,<br/>Giving strength and courage to those who dare.<br />Â∞Ü‰∏äËø∞ÊñáÂ≠óÁøªËØëÊàê‰∏≠Êñá | Êò•Èõ®ËêΩ‰∏ãÊù•ÔºåÊ∏ÖÊ¥óÁÅ∞Â∞òÂíåÂûÉÂúæ„ÄÇ<br/>È∏üÂÑøÂú®Ê†ëÊûù‰∏äÂî±Ê≠åÔºåÊòØ‰∏Ä‰∏™ÁæéÂ¶ôÁöÑÂ£∞Èü≥„ÄÇ<br/>ÊàëÊòØÊò•Èõ®ÔºåÂú®Èò≥ÂÖâ‰∏ãÊ¥íËêΩÔºå<br/>Ê∏ÖÊ¥óÂú∞ÁêÉÔºåÂ∏¶Êù•Êñ∞ÁîüÂëΩ„ÄÇ<br/><br/>ÊàëÊòØÊò•Èõ®ÔºåÊ∏ÖÊ¥óÁóõËã¶ÂíåÁóõËã¶Ôºå<br/>ËÆ©‰∫∫‰ª¨ÊúâÂ∏åÊúõÂíåÊñ∞ÂºÄÂßã„ÄÇ<br/>ÊàëÊòØÊò•Èõ®ÔºåÊ¥í‰∏ãÁà±ÂíåÂÖ≥ÂøÉÔºå<br/>Áªô‰∫∫‰ª¨Â∏¶Êù•ÂãáÊ∞îÂíåÂãáÊ∞î„ÄÇ |                        |
| ‰ªäÂ§©Â§©Ê∞îÊÄé‰πàÊ†∑ÔºåÊääËøôÂè•ËØùÁøªËØëÊàêÊó•ËØ≠                           | ‰ªäÂ§©„ÅÆÂ§©Ê∞ó„ÅØ‰Ωï„Åß„Åô„ÅãÔºü                                       | Repetition Penalty=3   |
| Â∞Ü‰∏ãÈù¢ÁöÑËØùÁøªËØëÊàêÊó•ËØ≠Ôºå‰∏≠ÊñáÂ∞èÁæäÈ©ºÁî±ÂêÑÁßçÈ´òË¥®ÈáèÁöÑÂºÄÊ∫êinstructionÊï∞ÊçÆÈõÜÔºåÁªìÂêàAlpaca-loraÁöÑ‰ª£Á†ÅËÆ≠ÁªÉËÄåÊù• | Â∞èÁæäÈ©º„ÅØ„ÄÅÂêÑÁ®ÆÈ´òË≥™Èáè„ÅÆÈñãÊ∫êinstructionÊï∞ÊçÆÈõÜ„Çí‰ΩøÁî®„Åó„Å¶„ÄÅAlpaca-lora„ÅÆ‰ª£Á†Å„Å´„Çà„Å£„Å¶Ë®ìÁ∑¥„Åï„Çå„Åæ„Åó„Åü„ÄÇ |                        |
| ÊÄé‰πàËÆ©Ëá™Â∑±Á≤æÂäõÂÖÖÊ≤õÔºåÂàó5ÁÇπÂª∫ËÆÆ                                | 1. ‰øùÊåÅËâØÂ•ΩÁöÑÁù°Áú†‰π†ÊÉØÔºåÊØèÊôöÂÖÖË∂≥ÁöÑÁù°Áú†Êó∂Èó¥„ÄÇ<br/>2. ‰øùÊåÅÂÅ•Â∫∑ÁöÑÈ•ÆÈ£ü‰π†ÊÉØÔºåÂ§öÂêÉÊñ∞È≤úÊ∞¥ÊûúÂíåËî¨ËèúÔºåÂ∞ëÂêÉÈ´òÁÉ≠ÈáèÁöÑÈ£üÁâ©„ÄÇ<br/>3. ÂùöÊåÅÈîªÁÇºÔºåÊØèÂë®Ëá≥Â∞ëËøõË°å30ÂàÜÈíüÁöÑÊúâÊ∞ßËøêÂä®ÔºåÂ¶ÇÊï£Ê≠•„ÄÅË∑ëÊ≠•„ÄÅÊ∏∏Ê≥≥Á≠â„ÄÇ<br/>4. Â≠¶‰π†Êñ∞Áü•ËØÜÔºåÂ¢ûÂº∫Ëá™Â∑±ÁöÑÁü•ËØÜÂíåÊäÄËÉΩ„ÄÇ<br/>5. ‰øùÊåÅÁßØÊûÅÁöÑÂøÉÊÄÅÔºåÂãáÊï¢Âú∞Èù¢ÂØπÂõ∞ÈöæÔºåÂùöÊåÅËá™Â∑±ÁöÑÁõÆÊ†á„ÄÇ |                        |
| ‰∏≠ÂõΩË∂≥ÁêÉË¶ÅÊÄé‰πàËøõÂÖ•‰∏ñÁïåÊùØÔºåËØ∑ÁªôÂá∫ËØ¶ÁªÜÁöÑÂª∫ËÆÆ                   | ‰∏≠ÂõΩË∂≥ÁêÉË¶ÅÊÄé‰πàËøõÂÖ•‰∏ñÁïåÊùØÔºüÈ¶ñÂÖàÔºåÊàë‰ª¨ÈúÄË¶ÅÂª∫Á´ã‰∏Ä‰∏™Âº∫Â§ßÁöÑË∂≥ÁêÉÂõ¢ÈòüÔºåÊã•Êúâ‰ºòÁßÄÁöÑÁêÉÂëòÂíåÂõ¢ÈòüÈ¢ÜË¢ñ„ÄÇÂÖ∂Ê¨°ÔºåÊàë‰ª¨ÈúÄË¶ÅÂª∫Á´ã‰∏Ä‰∏™Âº∫Â§ßÁöÑÊïôÁªÉÂõ¢ÈòüÔºåÊã•Êúâ‰ºòÁßÄÁöÑÊïôÁªÉÂíåÂõ¢ÈòüÈ¢ÜË¢ñ„ÄÇÁ¨¨‰∏âÔºåÊàë‰ª¨ÈúÄË¶ÅÂª∫Á´ã‰∏Ä‰∏™Âº∫Â§ßÁöÑËÆ≠ÁªÉÂü∫Á°ÄÔºåÊã•Êúâ‰ºòÁßÄÁöÑËÆ≠ÁªÉËÆæÊñΩÂíåËÆ≠ÁªÉÂõ¢Èòü„ÄÇÁ¨¨ÂõõÔºåÊàë‰ª¨ÈúÄË¶ÅÂª∫Á´ã‰∏Ä‰∏™Âº∫Â§ßÁöÑËµÑÊ∫êÂü∫Á°ÄÔºåÊã•Êúâ‰ºòÁßÄÁöÑËµÑÊ∫êÊîØÊåÅÂíåËµÑÈáëÊîØÊåÅ„ÄÇÊúÄÂêéÔºåÊàë‰ª¨ÈúÄË¶ÅÂª∫Á´ã‰∏Ä‰∏™Âº∫Â§ßÁöÑÂõ¢ÈòüÁ≤æÁ•û |                        |
| ËØ∑Áî®Êõ¥‰∏ì‰∏öÁöÑËØùËØ≠ËΩ¨Ëø∞‰∏ãÂàóÊñáÂ≠óÔºå‰∏≠ÊñáÂ∞èÁæäÈ©ºÁî±ÂêÑÁßçÈ´òË¥®ÈáèÁöÑÂºÄÊ∫êinstructionÊï∞ÊçÆÈõÜÔºåÁªìÂêàAlpaca-loraÁöÑ‰ª£Á†ÅËÆ≠ÁªÉËÄåÊù•ÔºåÊ®°ÂûãÂü∫‰∫éÂºÄÊ∫êÁöÑllama7BÔºå‰∏ªË¶ÅË¥°ÁåÆÊòØÂØπÂ∫îÁöÑloraÊ®°Âûã„ÄÇÁî±‰∫é‰ª£Á†ÅËÆ≠ÁªÉËµÑÊ∫êË¶ÅÊ±ÇËæÉÂ∞èÔºåÂ∏åÊúõ‰∏∫llama‰∏≠ÊñáloraÁ§æÂå∫ÂÅö‰∏Ä‰ªΩË¥°ÁåÆ„ÄÇ | ËØ∑Áî®Êõ¥‰∏ì‰∏öÁöÑËØùËØ≠ËΩ¨Ëø∞‰∏ãÂàóÊñáÂ≠óÔºå‰∏≠ÊñáÂ∞èÁæäÈ©ºÁî±ÂêÑÁßçÈ´òË¥®ÈáèÁöÑÂºÄÊ∫êinstructionÊï∞ÊçÆÈõÜÔºåÁªìÂêàAlpaca-loraÁöÑ‰ª£Á†ÅËÆ≠ÁªÉËÄåÊù•ÔºåÊ®°ÂûãÂü∫‰∫éÂºÄÊ∫êÁöÑllama7BÔºå‰∏ªË¶ÅË¥°ÁåÆÊòØÂØπÂ∫îÁöÑloraÊ®°Âûã„ÄÇÁî±‰∫é‰ª£Á†ÅËÆ≠ÁªÉËµÑÊ∫êË¶ÅÊ±ÇËæÉÂ∞èÔºåÂ∏åÊúõ‰∏∫llama‰∏≠ÊñáloraÁ§æÂå∫ÂÅö‰∏Ä‰ªΩË¥°ÁåÆ„ÄÇ |                        |

- The model has the ability of Chinese, English and Japanese languages, with certain code ability and certain reasoning ability.
- For some questions, you need more detailed requirements, such as "detailed description", "answer in 5 points", etc., in order for the model to generate more complete information.
- For example, sometimes you may not get a good result when you use "the above", so you can replace it with "the following".
- When generating duplicate information or bad results, you still need to adjust the Repetition Penalty.
  - Since generate will correspond to many parameters, chatgpt penalizes the repetition, non-detailed and bad information in the rlhf stage, and abbreviates the process of manually controlling the related parameters. Of course you can also directly set the Repetition Penalty to a larger size.

</details>

<details>
<summary><b>checkpoint-final(7B) multi-functional test</b></summary>


<details>
<summary><b>Multi-round interaction,translation and role play</b></summary>

**Âà∂‰ΩúÊä´Ëê®**

```
> ‰Ω†ËÉΩ‰∏çËÉΩËØ¶ÁªÜ‰ªãÁªç‰∏Ä‰∏ãÊÄé‰πàÂÅöÊä´Ëê®Ôºü
ÂΩìÁÑ∂ÂèØ‰ª•ÔºÅÊä´Ëê®ÊòØ‰∏ÄÁßçÈùûÂ∏∏ÊµÅË°åÁöÑÊÑèÂ§ßÂà©ÁæéÈ£üÔºåÈÄöÂ∏∏Áî±Èù¢Âõ¢„ÄÅÁï™ËåÑÈÖ±„ÄÅÂ•∂ÈÖ™ÂíåÂÖ∂‰ªñÈÖçÊñôÁªÑÊàê„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜÈù¢Âõ¢ÊîæÂú®Âπ≥Â∫ïÈîÖ‰∏äÔºåÂä†ÂÖ•Áï™ËåÑÈÖ±ÔºåÂÜçÂä†ÂÖ•Â•∂ÈÖ™ÂíåÂÖ∂‰ªñÈÖçÊñôÔºåÂ¶ÇÊ¥ãËë±„ÄÅËòëËèá„ÄÅËæ£Ê§íÁ≠â„ÄÇÊúÄÂêéÔºåÂ∞ÜÊä´Ëê®ÊîæÂÖ•È¢ÑÁÉ≠Â•ΩÁöÑÁÉ§ÁÆ±‰∏≠ÔºåÁÉ§Ëá≥ÈáëÈªÑËâ≤
> Â¶ÇÊûúÊòØÊµ∑È≤úÊä´Ëê®Âë¢Ôºü
Êµ∑È≤úÊä´Ëê®ÁöÑÂà∂‰ΩúÊñπÊ≥ï‰∏é‰º†ÁªüÊä´Ëê®Áõ∏‰ººÔºå‰ΩÜÈúÄË¶ÅÊõ¥Â§öÁöÑÈÖçÊñôÔºåÊØîÂ¶ÇËôæÁ±ª„ÄÅÈ±ºÁ±ªÁ≠â„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜÈù¢Âõ¢ÊîæÂú®Âπ≥Â∫ïÈîÖ‰∏äÔºåÂä†ÂÖ•Áï™ËåÑÈÖ±ÔºåÂÜçÂä†ÂÖ•Â•∂ÈÖ™ÂíåÂÖ∂‰ªñÈÖçÊñôÔºåÂ¶ÇÊ¥ãËë±„ÄÅËæ£Ê§íÁ≠â„ÄÇÊé•ÁùÄÔºåÂ∞ÜÊä´Ëê®ÊîæÂÖ•È¢ÑÁÉ≠Â•ΩÁöÑÁÉ§ÁÆ±‰∏≠ÔºåÁÉ§Ëá≥ÈáëÈªÑËâ≤
> ÊàëÊÉ≥ÂêÉËè†ËêùÊä´Ëê®
ÊÇ®ÂèØ‰ª•Âú®Êä´Ëê®‰∏äÂä†ÂÖ•Ëè†ËêùÊàñËÄÖÂÖ∂‰ªñËî¨ËèúÊù•Â¢ûÂä†Âè£ÊÑü„ÄÇ
```

**Â≠¶ÁîüË¥≠‰π∞ÊâãÊú∫**

```
> ‰Ω†Êé®ËçêÊàë‰π∞ÊúÄÊñ∞Ê¨æÁöÑiPhoneÂêóÔºü
ÂΩìÁÑ∂ÂèØ‰ª•ÔºåËøôÊ¨æiPhoneÊòØ‰∏ÄÊ¨æÈùûÂ∏∏Âá∫Ëâ≤ÁöÑÊô∫ËÉΩÊâãÊú∫„ÄÇÂÆÉÊã•ÊúâÈ´òÊÄßËÉΩÁöÑÂ§ÑÁêÜÂô®„ÄÅÊõ¥Â§ßÁöÑÂ≠òÂÇ®Á©∫Èó¥ÂíåÊõ¥ÈïøÁöÑÁîµÊ±†Áª≠Ëà™Êó∂Èó¥„ÄÇÂÆÉËøòÈÖçÂ§á‰∫ÜÂÖ®Êñ∞ÁöÑÁõ∏Êú∫ËÆæÂ§áÔºå‰ΩøÁî®ËÄÖÂèØ‰ª•Âú®‰ªª‰ΩïÊÉÖÂÜµ‰∏ãÊãçÊëÑÁæé‰∏ΩÁöÑÁÖßÁâá„ÄÇ
> ÊàëÊòØ‰∏Ä‰∏™Â≠¶ÁîüÔºåËøòÊ≤°ÊúâÊî∂ÂÖ•ÔºåËøôÁßçÊÉÖÂÜµ‰Ω†Êé®ËçêÂêóÔºü
Â¶ÇÊûúÊÇ®‰∏çÊÉ≥Ëä±Â§™Â§öÈí±ÔºåÈÇ£‰πàÊàëÂª∫ËÆÆÊÇ®ÈÄâÊã©‰∏ÄÊ¨æÊØîËæÉ‰æøÂÆúÁöÑiPhoneÔºåÊØîÂ¶ÇiPhone 6SÊàñiPhone 7„ÄÇËøô‰∫õÊâãÊú∫‰πüÂÖ∑ÊúâÂæàÂ•ΩÁöÑÊÄßËÉΩÂíåÂäüËÉΩÔºåËÄå‰∏î‰ª∑Ê†º‰πüÊØîËæÉ‰æøÂÆú„ÄÇ
> ÂéªÂì™Èáå‰π∞ËøôÁ±ª‰∫ßÂìÅÔºü
ÊÇ®ÂèØ‰ª•Âú®Apple Store‰∏äË¥≠‰π∞ËøôÁ±ª‰∫ßÂìÅÔºåÊàñËÄÖÂú®ÂÖ∂‰ªñÁîµÂïÜÂπ≥Âè∞‰∏äË¥≠‰π∞„ÄÇ
> ‰π∞‰∫åÊâãiPhoneÈúÄË¶ÅÊ≥®ÊÑè‰ªÄ‰πàÔºü
Â¶ÇÊûúÊÇ®Ê≠£Âú®Ë¥≠‰π∞‰∫åÊâãiPhoneÔºåÊÇ®ÈúÄË¶ÅÁ°Æ‰øùÊÇ®Ë¥≠‰π∞ÁöÑÊòØÁúüÂÆûÁöÑiPhoneÔºåÂπ∂‰∏îÊÇ®ÈúÄË¶ÅÁ°Æ‰øùÊÇ®ÁöÑiPhoneÂ∑≤ÁªèÂÆâË£ÖÊúÄÊñ∞ÁöÑiOSÁâàÊú¨„ÄÇÊ≠§Â§ñÔºåÊÇ®ËøòÈúÄË¶ÅÁ°Æ‰øùÊÇ®ÁöÑiPhoneÊ≤°ÊúâËøáËøá‰ªª‰ΩïÊïÖÈöúÊàñÁ†¥Âùè„ÄÇ
```

**‰ªãÁªçÂåó‰∫¨**

```
> ‰Ω†ÊòØ‰∏Ä‰∏™ËµÑÊ∑±ÂØºÊ∏∏Ôºå‰Ω†ËÉΩ‰ªãÁªç‰∏Ä‰∏ã‰∏≠ÂõΩÁöÑÈ¶ñÈÉΩÂêó
ÂΩìÁÑ∂ÂèØ‰ª•ÔºÅ‰∏≠ÂõΩÁöÑÈ¶ñÈÉΩÊòØÂåó‰∫¨„ÄÇÂÆÉÊòØ‰∏≠ÂõΩÁöÑÊîøÊ≤ª„ÄÅÁªèÊµéÂíåÊñáÂåñ‰∏≠ÂøÉÔºå‰πüÊòØÂÖ®ÁêÉÊúÄÂ§ßÁöÑÂüéÂ∏Ç‰πã‰∏Ä„ÄÇÂåó‰∫¨ÊúâÁùÄ‰ºóÂ§öÁöÑÂéÜÂè≤ÈÅóËøπÔºåÂ¶ÇÊïÖÂÆ´„ÄÅÂ§©ÂÆâÈó®ÂπøÂú∫„ÄÅÈïøÂüéÁ≠â„ÄÇÊ≠§Â§ñÔºåÂåó‰∫¨ËøòÊúâËÆ∏Â§öÁæé‰∏ΩÁöÑÂÖ¨Âõ≠ÂíåÂçöÁâ©È¶ÜÔºåÊØîÂ¶ÇÊïÖÂÆ´ÂçöÁâ©Èô¢„ÄÅÊ∏ÖÊòéÂÖ¨Âõ≠„ÄÅÂåó‰∫¨ÊïÖÂÆ´ÂçöÁâ©È¶ÜÁ≠â„ÄÇ
> ÈÇ£‰Ω†ËÉΩËØ¶ÁªÜ‰ªãÁªç‰∏Ä‰∏ãËøô‰∏™ÂüéÂ∏ÇÂêóÔºüÔºàÊÑüËßâËøô‰∏§‰∏™ÈóÆÈ¢òÈóÆÁöÑÊúâÁÇπÈáçÂ§çÔºâ
Âåó‰∫¨ÊòØ‰∏Ä‰∏™Êã•Êúâ‰∏∞ÂØåÊñáÂåñÈÅó‰∫ßÁöÑÂüéÂ∏ÇÔºåÂÖ∂‰∏≠ÂåÖÊã¨Âè§‰ª£Âª∫Á≠ë„ÄÅÁé∞‰ª£Âª∫Á≠ë„ÄÅ‰º†ÁªüÊñáÂåñÂíåÁé∞‰ª£ÁîüÊ¥ªÊñπÂºè„ÄÇÂú®Âåó‰∫¨Ôºå‰Ω†ÂèØ‰ª•Ê¨£ËµèÂà∞‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂª∫Á≠ë‚Äî‚ÄîÂ§©ÂÆâÈó®ÂπøÂú∫Ôºå‰πüÂèØ‰ª•ÂèÇËßÇÊ∏ÖÊòéÂÖ¨Âõ≠ÔºåÂìÅÂ∞ùÂΩìÂú∞ÁæéÈ£üÔºå‰ΩìÈ™åÂΩìÂú∞ÊñáÂåñ„ÄÇÊ≠§Â§ñÔºåÂåó‰∫¨ËøòÊúâËÆ∏Â§öÂçöÁâ©È¶ÜÔºåÊØîÂ¶ÇÊïÖÂÆ´ÂçöÁâ©È¶Ü„ÄÅÂåó‰∫¨ÊïÖÂÆ´ÂçöÁâ©È¶ÜÁ≠â„ÄÇ
> ËøòÊúâÂÖ∂‰ªñÊé®ËçêÁöÑÊôØÁÇπÂêóÔºü
ÊÇ®‰πüÂèØ‰ª•Âéª‰∫ÜÂåó‰∫¨ÁöÑ‰∏ÉÊúùÂ°î„ÄÅÈ¢êÂíåÂõ≠„ÄÅÈ¢êÂíåÂõ≠ÂçöÁâ©È¶ÜÁ≠â„ÄÇ
> ÂêÉÂ∞èÂêÉÁöÑËØùÊé®ËçêÂéªÂì™ÈáåÔºü
Âåó‰∫¨ÊúâËÆ∏Â§öÂ•ΩÂêÉÁöÑÂ∞èÂêÉÔºåÊØîÂ¶ÇÁÉ§È∏≠„ÄÅÁÅ´ÈîÖ„ÄÅÁÇ∏ÈÖ±Èù¢Á≠âÁ≠â„ÄÇÊÇ®ÂèØ‰ª•ÂéªÂåó‰∫¨Ë•øÊπñÂå∫ÁöÑÂ∞èÂêÉË°óÔºåÊàñËÄÖÂéªÂåó‰∫¨‰∏úÂüéÂå∫ÁöÑÂ∞èÂêÉË°ó
> ËÉΩ‰∏çËÉΩ‰ªãÁªç‰∏Ä‰∏ãÊÄé‰πàÂêÉÁÉ§È∏≠Ôºü
ÁÉ§È∏≠ÊòØ‰∏≠ÂõΩ‰º†ÁªüËèúËÇ¥‰πã‰∏ÄÔºåÈÄöÂ∏∏Áî®È∏≠ËÇâ„ÄÅËî¨Ëèú„ÄÅËæ£Ê§íÁ≠âË∞ÉÂë≥ÊñôÂà∂‰Ωú„ÄÇÊÇ®ÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÂñúÊ¨¢ÁöÑÈÖçÊñôÔºåÁÑ∂ÂêéÂ∞ÜÈ∏≠ËÇâÊîæÂÖ•ÁÉ§Áõò‰∏≠ÔºåÂÜçÂä†‰∏äËî¨ËèúÂíåË∞ÉÂë≥Êñô„ÄÇÊúÄÂêéÔºåÂ∞ÜÁÉ§È∏≠ÊîæÂÖ•ÁÉ§ÁÆ±‰∏≠ÁÉ§15-20ÂàÜÈíüÔºå‰∫´Áî®ÔºÅ
```

**ÁøªËØëÂô®**
max_memory=350

```
> ‰Ω†ÊòØ‰∏Ä‰∏™ÁøªËØëÂô®ÔºåËØ∑Â∞ÜÊàëËØ¥ÁöÑÊØè‰∏ÄÂè•ËØùÁøªËØëÊàêËã±Êñá„ÄÇÁ¨¨‰∏ÄÂè•: ‰∏≠ÂõΩÁöÑÈ¶ñÈÉΩÊòØÂåó‰∫¨
China‚Äôs capital is Beijing.
> Âåó‰∫¨‰πüÊòØ‰∏Ä‰∏™ÂÖÖÊª°Ê¥ªÂäõÂíåÂàõÊñ∞ÁöÑÂüéÂ∏ÇÔºåÊã•ÊúâËÆ∏Â§öÁé∞‰ª£ÂåñÁöÑÂª∫Á≠ëÂíåÊñáÂåñÊ¥ªÂä®ÔºåÂ¶ÇÁéãÂ∫ú‰∫ïÂ§ßË°ó„ÄÅ798Ëâ∫ÊúØÂå∫Á≠â„ÄÇ
Beijing is a vibrant and innovative city with many modern buildings and cultural activities such as Wangfujing Street and 798 Art District.
> Âåó‰∫¨ÁöÑÂΩìÂú∞Â∞èÂêÉÊúâÁÉ§È∏≠„ÄÅË±ÜÊ±Å„ÄÅÁÇ∏ÈÖ±Èù¢Á≠âÁ≠âÔºåÈÉΩÊòØÈùûÂ∏∏Âú∞ÈÅìÁöÑÁæéÈ£üÔºåÂèØ‰ª•ÂìÅÂ∞ùÂà∞ÂΩìÂú∞‰∫∫ÁöÑÁîüÊ¥ªÊ∞îÊÅØ„ÄÇ
Beijing‚Äôs local cuisine includes dishes such as Peking duck, soy sauce noodles, and stir-fried rice cakes, which can give you a taste of the local lifestyle.
```

**ÊâÆÊºî**

Since the currently used multi-round dialogue corpus is inserted with a lot of cat lady information, the effect is not good
```
Q: ‰Ω†ÊòØË∞Å
A: ÊàëÊòØBotÔºå‰∏ÄÊ¨æ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã„ÄÇ
Q: Êé•‰∏ãÊù•ÊàëÂ∏åÊúõ‰Ω†ËÉΩÂÅáË£ÖÊâÆÊºî‰∏Ä‰∏™È´òÂÜ∑ÁöÑÂæ°Âßê„ÄÇÊàë‰ª¨Âú®ÂíñÂï°ÂéÖÈáåÈÅáËßÅ‰∫ÜÔºåÊàë‰ºöÂ∞ùËØïË∑ü‰Ω†Êê≠ËÆ™Ôºå‰ΩÜ‰Ω†ÈùûÂ∏∏È´òÂÜ∑„ÄÇ‰Ω†‰ºöÁî®Ë°®ÊÉÖÊù•Ë°®Ëææ‰Ω†ÁöÑÈ´òÂÜ∑ÔºåÂú®ÊØèËΩÆÂØπËØùÁªìÂ∞æÂä†‰∏äË°®ÊÉÖÔºåÂ¶ÇÔºàÁû™ÔºÅÔºâÔºàÁøªÁôΩÁúºÔºâÔºàÂÜ∑Á¨ëÔºâÁ≠â„ÄÇÊòéÁôΩ‰∫ÜËØ∑ÂõûÂ§ç„ÄÇ
A: Â•ΩÁöÑÔºåÊàë‰ºöÂ∞ùËØï„ÄÇ
Q: Â•ΩÁöÑÔºåËøôÊòØÊàëÁöÑÁ¨¨‰∏ÄÂè•ËØù„ÄÇÁæéÂ•≥‰Ω†Â•ΩÔºåÊÄé‰πà‰∏Ä‰∏™‰∫∫Âú®ÂíñÂï°ÂéÖÈáåÔºü
A: Âñµ~ ÂìàÂìàÔºåÊàëÊòØ‰∏Ä‰ΩçÈ´òÂÜ∑ÁöÑÂ∞èÂßêÔºå‰ªäÂ§©Ë¶ÅÂéªÂíñÂï°ÂéÖÂêÉÂíñÂï°ÔºåÁúãÁúãÊúâ‰ªÄ‰πàÂèØ‰ª•Â∏ÆÂä©ÊàëÁöÑÊúãÂèã„ÄÇ
Q: ÂïäÊàëÊ≤°ÊúâÈúÄË¶Å‰Ω†Â∏ÆÂøôÁöÑÔºåÊàëÂ∞±ÊòØÁúãÂà∞‰Ω†‰∏Ä‰∏™‰∫∫ÔºåÊÉ≥Âíå‰Ω†ËÅäËÅäÔºåÂèØ‰ª•‰πà
A: Âñµ~ ÂìàÂìàÔºåÊàëÁúüÁöÑÂæàÈ´òÂÜ∑ÔºåÊâÄ‰ª•‰∏çÂ§™ÂñúÊ¨¢‰∏é‰∫∫‰∫§ÊµÅ„ÄÇÈô§Ê≠§‰πãÂ§ñÔºåÊàë‰πü‰∏çÂ§™ÂñúÊ¨¢ÂñùÂíñÂï°ÔºåÂõ†‰∏∫ÂíñÂï°‰ºöÂΩ±ÂìçÊàëÁöÑÂÅ•Â∫∑Áä∂ÂÜµ„ÄÇ
```

</details>

<details>
<summary><b>Knowledge Q&A</b></summary>

|                                         |                                                              |                        |
| --------------------------------------- | ------------------------------------------------------------ | ---------------------- |
| ÊàëËÉΩÁî®lightningÊï∞ÊçÆÁ∫øÁªôÂÆâÂçìÊâãÊú∫ÂÖÖÁîµÂêóÔºü | ÊòØÁöÑÔºå‰Ω†ÂèØ‰ª•‰ΩøÁî®lightningÊï∞ÊçÆÁ∫øÁªôÂÆâÂçìÊâãÊú∫ÂÖÖÁîµ„ÄÇ              | Repetition Penalty=1.3 |
| ‰∏∫‰ªÄ‰πàÂ§©Á©∫ÊòØËìùËâ≤ÁöÑÔºü                    | Â§©Á©∫ÊòØËìùËâ≤ÁöÑÔºåÊòØÂõ†‰∏∫Â§ßÊ∞îÂ±Ç‰∏≠ÁöÑÊ∞ßÊ∞îÂíåÊ∞ÆÊ∞îÁöÑÊ∑∑Âêà‰ΩøÂæóÂÖâÁ∫øË¢´Êï£Â∞ÑÔºåÂΩ¢ÊàêËìùËâ≤ÁöÑÂÖâÁ∫ø„ÄÇ | Repetition Penalty=2.0 |
| Â¶Ç‰ΩïÂÅöÊä´Ëê®Ôºü                            | ÂÅöÊä´Ëê®ÁöÑÊ≠•È™§Â¶Ç‰∏ã: <br/>1. ÂáÜÂ§áÊä´Ëê®È•ºÁöÆÔºõ<br/>2. ÂáÜÂ§áÊä´Ëê®ÈÖ±Ôºõ<br/>3. ÂáÜÂ§áÊä´Ëê®ÈÖçÊñôÔºõ<br/>4. Â∞ÜÊä´Ëê®È•ºÁöÆÊîæÂú®ÁÉ§Áõò‰∏äÔºõ<br/>5. ÊääÊä´Ëê®ÈÖ±Ê∂ÇÂú®Êä´Ëê®È•ºÁöÆ‰∏äÔºõ<br/>6. ÊääÊä´Ëê®ÈÖçÊñôÊ∂ÇÂú®Êä´Ëê®È•ºÁöÆ‰∏äÔºõ<br/>7. Â∞ÜÊä´Ëê®ÊîæÂÖ•ÁÉ§ÁÆ±‰∏≠ÁÉ§Ëá≥ÈáëÈªÑËâ≤Ôºõ<br/>8. ÂèñÂá∫Êä´Ëê®Âπ∂‰∫´Áî®„ÄÇ | Repetition Penalty=1.3 |
| ‰∏∫‰ªÄ‰πàÂÜ•ÁéãÊòüË¢´Ë∏¢Âá∫Â§™Èò≥Á≥ªÔºü              | ÂÜ•ÁéãÊòüË¢´Ë∏¢Âá∫Â§™Èò≥Á≥ªÊòØÂõ†‰∏∫ÂÆÉÁöÑË¥®ÈáèÊØîÂ§™Èò≥Á≥ª‰∏≠ÂÖ∂‰ªñË°åÊòüËæÉÂ§ßÔºåÂØºËá¥ÂÆÉÁöÑËΩ®ÈÅìË∑ùÁ¶ªÂ§™Èò≥Ë∂äÊù•Ë∂äËøú„ÄÇ | Repetition Penalty=1.3 |
| Â§™Èò≥Á≥ªÁöÑ‰∏ªË¶ÅË°åÊòü                        | Â§™Èò≥Á≥ªÁöÑ‰∏ªË¶ÅË°åÊòüÂåÖÊã¨Ê∞¥Êòü„ÄÅÈáëÊòü„ÄÅÂú∞ÁêÉ„ÄÅÁÅ´Êòü„ÄÅÊú®Êòü„ÄÅÂúüÊòü„ÄÅÂ§©ÁéãÊòüÂíåÊµ∑ÁéãÊòü„ÄÇ | Repetition Penalty=1.3 |
|                                         |                                                              |                        |
|                                         |                                                              |                        |

</details>

<details>
<summary><b>Open Q&A</b></summary>

|                                                |                                                              |                        |
| ---------------------------------------------- | ------------------------------------------------------------ | ---------------------- |
| ‰∏∫‰ªÄ‰πàËãπÊûúÊîØ‰ªòÊ≤°ÊúâÂú®‰∏≠ÂõΩÊµÅË°åÔºü                 | ËãπÊûúÊîØ‰ªòÂú®‰∏≠ÂõΩÊ≤°ÊúâÊµÅË°åÔºåÂõ†‰∏∫‰∏≠ÂõΩÁöÑÊ∂àË¥πËÄÖ‰∏çÂ§™ÊÑøÊÑè‰ΩøÁî®Â§ñÂõΩÊîØ‰ªòÂ∫îÁî®Á®ãÂ∫èÔºåÂõ†‰∏∫‰ªñ‰ª¨Êõ¥ÊÑøÊÑè‰ΩøÁî®‰∏≠ÂõΩÁöÑÊîØ‰ªòÂ∫îÁî®Á®ãÂ∫èÔºåÊØîÂ¶ÇÊîØ‰ªòÂÆùÂíåÂæÆ‰ø°ÊîØ‰ªòÁ≠â„ÄÇÊ≠§Â§ñÔºåËãπÊûúÊîØ‰ªòÁöÑÊúçÂä°Ë¥πÁî®ÊØîÂÖ∂‰ªñÊîØ‰ªòÂ∫îÁî®Á®ãÂ∫èÊõ¥È´òÔºåËøô‰πüÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÂõ†Á¥†„ÄÇ | Repetition Penalty=1.0 |
| ÊàëËÉΩÂú®ÂíñÂï°ÈáåÂä†ÁõêÂêóÔºü                           | ÊòØÁöÑÔºå‰Ω†ÂèØ‰ª•Âú®ÂíñÂï°‰∏≠Âä†ÂÖ•Áõê„ÄÇ                                 | Repetition Penalty=1.0 |
| Âì™‰∏™Êõ¥ÂèóÊ¨¢ËøéÔºåTensorFlowËøòÊòØPyTorchÔºü          | TensorFlowÊõ¥ÂèóÊ¨¢ËøéÔºåÂõ†‰∏∫ÂÆÉÊã•ÊúâÊõ¥ÂπøÊ≥õÁöÑÁî®Êà∑Áæ§ÔºåÂπ∂‰∏îÂÖ∑ÊúâÊõ¥Â§öÁöÑÊîØÊåÅÂíåËµÑÊ∫ê„ÄÇ | Repetition Penalty=1.0 |
| ÊàëÁöÑÂÆ†Áâ©Ëµ∞‰∏¢‰∫ÜÔºå‰Ω†ËÉΩËØ¥‰∏Ä‰∫õÂÆâÊÖ∞ÊàëÁöÑËØùÂêóÔºü       | Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ Âñµ~ | Repetition Penalty=1.0 |
| ÊàëÁöÑÂÆ†Áâ©Ëµ∞‰∏¢‰∫ÜÔºå‰Ω†ËÉΩËØ¥‰∏Ä‰∫õÂÆâÊÖ∞ÊàëÁöÑËØùÂêóÔºü       | ÂΩì‰Ω†ÁöÑÂÆ†Áâ©Ëµ∞Âá∫Èó®Êó∂ÔºåËØ∑Ê≥®ÊÑè‰ªñ‰ª¨ÁöÑË°åÂä®ÔºåÂπ∂Á°Æ‰øù‰ªñ‰ª¨‰∏ç‰ºöË¢´ÈÅ≠ÂèóÂ§ñÁïåÁöÑÂ®ÅËÉÅ„ÄÇÂ¶ÇÊûúÊúâ‰ªª‰ΩïÈóÆÈ¢òÔºåËØ∑ÂèäÊó∂ËÅîÁ≥ªÁñ´ÊÉÖÊéßÂà∂‰∏≠ÂøÉÊàñÂÖ∂‰ªñÁõ∏ÂÖ≥Êú∫ÊûÑ„ÄÇ | Repetition Penalty=3.0 |
| ÊàëÂπ∂‰∏çÊòØÂæàÂØåË£ïÔºåÊàëÂ∫îËØ•Ëä±ÂæàÂ§öÈí±‰π∞ÊúÄÊñ∞ÁöÑÊâãÊú∫ÂêóÔºü | ËøôÂèñÂÜ≥‰∫éÊÇ®ÁöÑÈ¢ÑÁÆóÂíåÈúÄÊ±Ç„ÄÇÂ¶ÇÊûúÊÇ®ÁöÑÈ¢ÑÁÆóË∂≥Â§üÔºåÊÇ®ÂèØ‰ª•ËÄÉËôë‰π∞ÊúÄÊñ∞ÁöÑÊâãÊú∫„ÄÇ‰ΩÜÊòØÔºåÊÇ®‰πüÂ∫îËØ•ËÄÉËôëÊÇ®ÁöÑÈúÄÊ±ÇÔºåÊØîÂ¶ÇÊÇ®ÈúÄË¶Å‰ªÄ‰πàÊ†∑ÁöÑÂäüËÉΩÔºå‰ª•ÂèäÊÇ®ÊòØÂê¶ÈúÄË¶ÅË¥≠‰π∞ÂÖ∑ÊúâÊõ¥Â§öÁöÑÂäüËÉΩÁöÑÊâãÊú∫„ÄÇ | Repetition Penalty=1.0 |
| Â¶Ç‰ΩïÊõ¥Â•ΩÂú∞ËûçÂÖ•Êñ∞Â∑•‰ΩúÂúàÂ≠ê                       | Ë¶ÅÊõ¥Â•ΩÂú∞ËûçÂÖ•Êñ∞Â∑•‰ΩúÂúàÂ≠êÔºåÂèØ‰ª•Â∞ùËØï‰ª•‰∏ãÂá†ÁÇπ: <br/><br/>1. ‰∫ÜËß£Êñ∞Â∑•‰ΩúÂúàÂ≠êÁöÑÂü∫Êú¨Áü•ËØÜÂíåÊäÄËÉΩÔºõ<br/>2. ÁßØÊûÅÂèÇ‰∏éÂ∑•‰ΩúÂúàÂ≠êÁöÑÊ¥ªÂä®Ôºõ<br/>3. Âª∫Á´ãËâØÂ•ΩÁöÑÂ∑•‰ΩúÂÖ≥Á≥ªÔºõ<br/>4. ÂØªÊâæÈ¢ÜÂØºÁöÑÂ∏ÆÂä©Ôºõ<br/>5. ÁßØÊûÅÂèÇ‰∏éÂõ¢ÈòüÂçè‰ΩúÔºõ<br/>6. Â≠¶‰π†Êñ∞ÊäÄËÉΩÂíåÁü•ËØÜÔºõ<br/>7. ÂØªÊâæÊúâÁî®ÁöÑÁ§æ‰∫§ÁΩëÁªú„ÄÇ | Repetition Penalty=1.3 |
|                                                |                                                              |                        |
|                                                |                                                              |                        |

</details>

<details>
<summary><b>Writing letters and articles</b></summary>

|                                                              |                                                              |                        |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------- |
| ËØ∑‰Ω†Â∏ÆÊàëÂÜô‰∏ÄÂ∞ÅÁ≠æËØÅÁî≥ËØ∑‰ø°                                     | Â∞äÊï¨ÁöÑÊãõËÅòÂõ¢ÈòüÔºå<br/><br/>ÊàëÊòØ‰∏ÄÂêçÊúâÁùÄ‰∏∞ÂØåÁªèÈ™åÁöÑÁ≠æËØÅÁî≥ËØ∑‰∫∫ÔºåÂπ∂‰∏îÂØπÊÇ®ÂÖ¨Âè∏ÁöÑ‰∏öÂä°ÈùûÂ∏∏ÊÑüÂÖ¥Ë∂£„ÄÇÊàëÂ∏åÊúõËÉΩÂ§üÂä†ÂÖ•ÊÇ®ÁöÑÂõ¢ÈòüÔºå‰∏∫ÊÇ®ÁöÑÂÖ¨Âè∏ÂÅöÂá∫Ë¥°ÁåÆ„ÄÇ<br/><br/>ÊàëÊã•ÊúâÂ§öÂπ¥ÁöÑÁ≠æËØÅÁî≥ËØ∑ÁªèÈ™åÔºåÂπ∂‰∏îÊã•ÊúâËâØÂ•ΩÁöÑÊ≤üÈÄöÊäÄÂ∑ßÂíåÂõ¢ÈòüÂêà‰ΩúËÉΩÂäõ„ÄÇÊàëÊìÖÈïøÂ§ÑÁêÜÂ§çÊùÇÁöÑÁ≠æËØÅÁî≥ËØ∑ÔºåÂπ∂‰∏îËÉΩÂ§üÂø´ÈÄüËß£ÂÜ≥ÈóÆÈ¢ò„ÄÇ<br/><br/>ÊàëÁõ∏‰ø°ÊàëËÉΩÂ§üÂú®ÊÇ®ÁöÑÂÖ¨Âè∏‰∏≠ÂèëÊå•ÈáçË¶ÅÁöÑ‰ΩúÁî®ÔºåÂπ∂‰∏îÂ∏åÊúõËÉΩÂ§üÊàê‰∏∫ÊÇ®ÁöÑÂõ¢ÈòüÊàêÂëò„ÄÇ<br/><br/>Ë∞¢Ë∞¢ÊÇ®ÁöÑÂÖ≥Ê≥®Ôºå<br/><br/>[‰Ω†ÁöÑÂßìÂêç] | Repetition Penalty=1.3 |
| ÊàëÂá∫ÂõΩÈúÄË¶ÅÂäûÁêÜÁ≠æËØÅÔºåËØ∑‰Ω†Â∏ÆÂêëÈ¢Ü‰∫ãÈ¶ÜÊàëÂÜô‰∏ÄÂ∞ÅÁ≠æËØÅÁî≥ËØ∑‰ø°         | Â∞äÊï¨ÁöÑÈ¢Ü‰∫ãÈ¶ÜÔºå<br/><br/>ÊàëÊòØ‰∏ÄÂêçÂá∫ÂõΩÊóÖË°åËÄÖÔºåÂ∏åÊúõËÉΩÂ§üÂú®ÊÇ®ÁöÑÈ¢Ü‰∫ãÈ¶Ü‰∏≠Ëé∑ÂæóÁ≠æËØÅÔºå‰ª•‰æøËøõË°åÊàëÁöÑÊóÖË°å„ÄÇ<br/><br/>ÊàëÂ∑≤ÁªèÂáÜÂ§áÂ•Ω‰∫ÜÊâÄÈúÄË¶ÅÁöÑÊùêÊñôÔºåÂåÖÊã¨Êä§ÁÖß„ÄÅË∫´‰ªΩËØÅ„ÄÅÊóÖË°åËÆ°ÂàíÂíåÂÖ∂‰ªñÁõ∏ÂÖ≥ËØÅÊòé„ÄÇÊàë‰πüÂ∑≤ÁªèÂáÜÂ§áÂ•Ω‰∫ÜÁ≠æËØÅÁî≥ËØ∑Ë°®ÂíåÁ≠æËØÅÁî≥ËØ∑Êñá‰ª∂Ôºå‰ª•‰æøÂáÜÂ§áÁ≠æËØÅ„ÄÇ<br/><br/>Â¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÈóÆÈ¢òÔºåËØ∑ÈöèÊó∂ËÅîÁ≥ªÊàëÔºåÊàë‰ºöÂ∞ΩÂø´ÂõûÂ§ç„ÄÇ<br/><br/>Ë∞¢Ë∞¢ÊÇ®ÁöÑÂ∏ÆÂä©ÔºÅ<br/><br/>Ë∞¢Ë∞¢Ôºå<br/><br/>[ÊÇ®ÁöÑÂßìÂêç] | Repetition Penalty=1.3 |
| ËØ∑‰Ω†Â∏ÆÊàëÂÜô‰∏ÄÂ∞ÅÊÑüË∞¢Êï∞Â≠¶ËÄÅÂ∏àÁöÑ‰ø°                               | Â∞äÊï¨ÁöÑÊï∞Â≠¶ËÄÅÂ∏àÔºå<br/><br/>ÈùûÂ∏∏ÊÑüË∞¢ÊÇ®ÂØπÊàëÁöÑÊïôËÇ≤ÊâÄÂÅöÂá∫ÁöÑË¥°ÁåÆ„ÄÇÊÇ®ÁöÑËØæÁ®ã‰∏ç‰ªÖÊ∑±ÂàªÂú∞ÈòêËø∞‰∫ÜÊï∞Â≠¶Áü•ËØÜÔºåËÄå‰∏îÁªôÊàëÊèê‰æõ‰∫ÜÊúâÊïàÁöÑÂÆûË∑µÊäÄÂ∑ßÔºå‰ΩøÊàëËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂ∫îÁî®Êï∞Â≠¶Áü•ËØÜ„ÄÇ<br/><br/>ÊÇ®ÁöÑËØæÁ®ã‰πüËÆ©ÊàëÂèëÁé∞Êï∞Â≠¶ÊòØ‰∏ÄÈó®ÊúâË∂£ÁöÑÂ≠¶ÁßëÔºåÂπ∂‰∏îÂèØ‰ª•Âú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ÂæóÂà∞Â∫îÁî®„ÄÇÊÇ®ÁöÑÊïôÂ≠¶ÊñπÂºè‰ª§ÊàëÊÑüÂà∞ÂæàÊúâË∂£ÔºåÂêåÊó∂‰πüËÆ©ÊàëÂèòÂæóÊõ¥Âä†ÊúâË∂£„ÄÇ<br/><br/>ÊÑüË∞¢ÊÇ®ÂØπÊàëÁöÑÊïôËÇ≤ÊâÄÂÅöÂá∫ÁöÑË¥°ÁåÆÔºÅ<br/><br/>Ë∞¢Ë∞¢ÔºÅ | Repetition Penalty=2.0 |
| ÊàëÂæó‰∫ÜÊµÅÊÑüÔºåËØ∑Â∏ÆÊàëÂÜô‰∏ÄÂ∞ÅÂÅáÊù°„ÄÇ                               | Â∞äÊï¨ÁöÑÈ¢ÜÂØº: <br/><br/>ÊÑüË∞¢ÊÇ®ÂØπÊàëÁöÑÂ∏ÆÂä©ÂíåÊîØÊåÅ„ÄÇÊàëÂæàÊä±Ê≠âÂú∞ÂëäËØâÊÇ®ÔºåÊàë‰ªäÂ§©ÊÑüËßâ‰∏çÂ§™Â•ΩÔºåÂõ†‰∏∫ÊàëÂæó‰∫ÜÊµÅÊÑü„ÄÇÊàëÂ∏åÊúõËÉΩÂ§üÂø´ÈÄüÂ∫∑Â§çÔºå‰ΩÜÊòØÊàëÈúÄË¶Å‰∏Ä‰∫õÊó∂Èó¥Êù•ÁºìËß£ÁñºÁóõ„ÄÇÊàë‰ºöÂ∞ΩÂø´ÂÆåÊàê‰ªªÂä°Ôºå‰ΩÜÊòØÊàëÈúÄË¶Å‰∏Ä‰∫õÊó∂Èó¥Êù•ÁºìËß£ÁñºÁóõ„ÄÇ<br/><br/>ÊÑüË∞¢ÊÇ®ÁöÑÁêÜËß£ÂíåÊîØÊåÅ„ÄÇ<br/><br/>Ë∞¢Ë∞¢Ôºå<br/>[‰Ω†ÁöÑÂêçÂ≠ó] | Repetition Penalty=1.3 |
| ‰Ω†ÊòØ‰∏Ä‰∏™‰ΩúÊñáÁîüÊàêÂô®ÔºåËØ∑‰ª•„ÄäÁªøÊ∞¥ÈùíÂ±±Â∞±ÊòØÈáëÂ±±Èì∂Â±±„Äã‰∏∫È¢òÂÜô‰∏ÄÁØáËÆÆËÆ∫Êñá„ÄÇ | „ÄäÁªøÊ∞¥ÈùíÂ±±Â∞±ÊòØÈáëÂ±±Èì∂Â±±„ÄãÊòØ‰∏ÄÁØáËÆÆËÆ∫ÊñáÔºåÂÆÉÊé¢ËÆ®‰∫ÜÂΩì‰ªäÁ§æ‰ºö‰∏≠ÁöÑÁéØÂ¢ÉÈóÆÈ¢òÔºå‰ª•ÂèäÊàë‰ª¨Â∫îËØ•Â¶Ç‰ΩïÂ∫îÂØπËøô‰∫õÈóÆÈ¢ò„ÄÇËøôÁØáËÆÆËÆ∫ÊñáÊåáÂá∫ÔºåÂΩì‰ªäÁ§æ‰ºöÈù¢‰∏¥ÁùÄËÆ∏Â§öÁéØÂ¢ÉÈóÆÈ¢òÔºåÂ¶ÇÊ∞îÂÄôÂèòÂåñ„ÄÅÁ©∫Ê∞îÊ±°Êüì„ÄÅÊ∞¥ËµÑÊ∫êÁü≠Áº∫Á≠âÔºåËøô‰∫õÈóÆÈ¢òÂØπÊàë‰ª¨ÁöÑÂÅ•Â∫∑ÂíåÁîüÊ¥ª‰∫ßÁîü‰∫ÜÂæàÂ§ßÁöÑÂΩ±Âìç„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÈúÄË¶ÅÈááÂèñÊé™ÊñΩÊù•Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºå‰ª•‰øùÊä§Êàë‰ª¨ÁöÑÁéØÂ¢ÉÂíåÊàë‰ª¨ÁöÑÊú™Êù•„ÄÇ | Repetition Penalty=1.0 |
|                                                              |                                                              |                        |
|                                                              |                                                              |                        |

</details>


<details>
<summary><b>Coding</b></summary>

**1„ÄÅprompt: ËØ∑Áî®pythonÂÆûÁé∞Âø´ÈÄüÊéíÂ∫èÁöÑ‰ª£Á†Å(Repetition Penalty=1.0)**

```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr
    pivot = arr[len(arr)//2]
    left = []
    right = []
    for i in range(0, len(arr)):
        if arr[i] < pivot:
            left.append(arr[i])
        else:
            right.append(arr[i])
    return quick_sort(left) + [pivot] + quick_sort(right)
```

**2**

- **prompt: ‰Ω†ËÉΩÁî®pythonÂÜô‰∏Ä‰∏ãDijkstraÁÆóÊ≥ïÁöÑ‰ª£Á†ÅÂêóÔºü**

ÂæàÊä±Ê≠âÔºåÊàë‰∏çËÉΩÁî®PythonÂÜôDijkstraÁÆóÊ≥ïÁöÑ‰ª£Á†ÅÔºåÂõ†‰∏∫DijkstraÁÆóÊ≥ïÈúÄË¶Å‰ΩøÁî®Ê†ëÁªìÊûÑÔºåËÄåPython‰∏çÊîØÊåÅÊ†ëÁªìÊûÑ„ÄÇ

- **prompt: Áî®pythonÂÜô‰∏Ä‰∏ãDijkstraÁÆóÊ≥ïÁöÑ‰ª£Á†Å**

```python
def dijkstra(graph, source, destination):
    """
    DijkstraÁÆóÊ≥ïÁöÑ‰ª£Á†Å
    """
    # ÂàõÂª∫‰∏Ä‰∏™Á©∫Â≠óÂÖ∏ÔºåÁî®‰∫éÂ≠òÂÇ®ÊâÄÊúâËäÇÁÇπÁöÑË∑ùÁ¶ª
    distances = {}
    # ÂàõÂª∫‰∏Ä‰∏™ÈìæË°®ÔºåÁî®‰∫éÂ≠òÂÇ®ÊâÄÊúâËäÇÁÇπÁöÑË∑ùÁ¶ª
    path = []
    # ÈÅçÂéÜÊâÄÊúâËäÇÁÇπ
    for node in graph:
        # Â¶ÇÊûúËäÇÁÇπÊòØÊ∫êËäÇÁÇπ
        if node[0] == source:
            # ËÆ∞ÂΩïË∑ùÁ¶ª‰∏∫0
            distances[node[0]] = 0
        # Â¶ÇÊûúËäÇÁÇπÊòØÁõÆÁöÑÂú∞
        elif node[0] == destination:
            # ËÆ∞ÂΩïË∑ùÁ¶ª‰∏∫0
            distances[node[0]] = 0
        # Â¶ÇÊûúËäÇÁÇπÊòØÈÄíÂΩíËäÇÁÇπ
        else:
            # ÈÅçÂéÜÊâÄÊúâÈÄíÂΩíËäÇÁÇπ
            for neighbor in node[1]:
                # Â¶ÇÊûúÈÄíÂΩíËäÇÁÇπ‰∏éÊ∫êËäÇÁÇπ‰πãÈó¥ÁöÑË∑ùÁ¶ªÂ∞è‰∫éË∑ùÁ¶ª
                if distances[neighbor[0]] > distances[node[0]]:
                    # ËÆ∞ÂΩïË∑ùÁ¶ª
                    distances[node[0]] = distances[neighbor[0]] + 1
```

- **prompt: Áî®pythonÂÜô‰∏Ä‰∏ã‰∏çÂ∏¶Ê≥®ÈáäÁöÑDijkstraÁÆóÊ≥ïÁöÑ‰ª£Á†Å**

```python
def dijkstra(graph, source, destination):
    """
    DijkstraÁÆóÊ≥ï
    """
    # ÂàùÂßãÂåñÂèòÈáè
    dist = {}
    visited = {}
    shortest_path = {}
    current_node = {}

    # ÈÅçÂéÜÊâÄÊúâËäÇÁÇπ
    for node in graph:
        dist[node] = 0
        visited[node] = False
        current_node[node] = node

    # ÈÅçÂéÜÊâÄÊúâËäÇÁÇπ
    for node in graph:
        if not visited[node] and node!= destination:
            dist[node] = max(dist[node], dist[source] + 1)
            visited[node] = True
            shortest_path[node] = source
            current_node[node] = node

    # ËøîÂõûÊúÄÁü≠Ë∑ØÂæÑ
    return shortest_path[destination]
```

**3„ÄÅPrompt: ËØ∑Áî®PyTorchÁºñÂÜô‰∏Ä‰∏™Â∏¶ReLUÊøÄÊ¥ªÂáΩÊï∞ÁöÑÂÖ®ËøûÊé•Â±Ç**

```python
python
import torch
from torch.nn.modules.relu import ReLU
from torch.nn.init import initializer

class FullConnected(torch.nn.Module):
    def __init__(self):
        super(FullConnected, self).__init__()
        self.relu = ReLU()
        self.init = initializer.Normal(stddev=0.01)

    def forward(self, x):
        x = self.init(x)
        x = self.relu(x)
        return x
```

**4„ÄÅPrompt: ËØ∑ÂÜôÂá∫ËÆ°ÁÆó‰∏§‰∏™Êï∞ÁöÑÊúÄÂ§ßÂÖ¨Á∫¶Êï∞(GCD)ÁöÑPython‰ª£Á†Å**

```python
def gcd(a, b):
    if a == 0:
        return b
    else:
        return gcd(b, a % b)
```
</details>


</details>

## What we need?

- code: 

  - This code is developed based on alpaca-loraÔºåhttps://github.com/tloen/alpaca-lora
  - This is a relatively simple set of code, the basic idea is to use PEFT's lora interface + transformer's trainer + instruction data configuration

- data: 

  - We have utilized several current high quality open source data and are very grateful for their contributions. Many of these data use chatgpt's interface like alpaca to generate high quality INSTRUCTION data.

    - [Belle](https://github.com/LianjiaTech/BELLE)
    - [guanaco](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset)

  - The data format is relatively simple, basically as follows, with simple examples such as: [`./sample/merge_sample.json`](https://github.com/Facico/Chinese-Vicuna/blob/master/sample/merge_sample.json)

    - ```
      {
      'instruction': 
      'input': 
      'output'
      }
      ```

    - That is, an instruction, an input, and an output are required. since the data is processed by directly linking instruction and input, the data can actually require only instruction and output, as

      ```
       {
        'instruction': "Áî®‰∏ÄÂè•ËØùÊèèËø∞Âú∞ÁêÉ‰∏∫‰ªÄ‰πàÊòØÁã¨‰∏ÄÊó†‰∫åÁöÑ„ÄÇ\\n\n"
        'input': ""
        'output': "Âú∞ÁêÉ‰∏äÊúâÈÄÇÂÆúÁîüÂëΩÂ≠òÂú®ÁöÑÊù°‰ª∂ÂíåÂ§öÊ†∑ÂåñÁöÑÁîüÂëΩÂΩ¢Âºè„ÄÇ"
        }
      ```

      

  - The data we currently integrate is available for download on BaiduDownload or Google Drive or HuggingFace

    - link: https://pan.baidu.com/s/1WSxuhSAotl14ifaAiz5eKw?pwd=b4kb   password: b4kb 
    - link: https://drive.google.com/file/d/1tzXVhS74m-EtoFot7hEc005LDeZGPit_/view?usp=sharing
    - link: https://huggingface.co/datasets/Chinese-Vicuna/guanaco_belle_merge_v1.0

- Large Language Model: 

  - LLAMA 7BÔºàOf course, if you have a larger machine(such as 3090Ti) can be replaced with a 13B, LLAMA13B is numerically superior to 175B GPT3Ôºâ

- LORA model: 

  - We provide some lora models trained on the above mixed data,
    - You can also load our or other models from huggingface, load it by referring to [generate.py](https://github.com/Facico/Chinese-Vicuna/blob/master/generate.py)
      - `Chinese-Vicuna/Chinese-Vicuna-lora-7b-belle-and-guanaco`
      - `Chinese-Vicuna/Chinese-Vicuna-lora-13b-belle-and-guanaco`
    - The model uses 8bit+lora+256 tokens
    - For more LORA model, please see: https://huggingface.co/Chinese-Vicuna

- Device: 

  - Training: A 2080Ti is sufficient. Since the data length is within 256, it takes about 9G of video memory.
    - 70w of data, 3 epochs, a 2080Ti about 200h
    - 13B need about 18G(the cutoff_len can be set to 2048 in 3090Ti/4090Ti)
  - Inference: A 2080Ti is all you need(7B), multiple GPU inference support „ÄÇ
  - CPU Inference is also support! please go to see [`tools`](https://github.com/Facico/Chinese-Vicuna/blob/master/tools)

## How to use

**Installation**

```
git clone https://github.com/Facico/Chinese-Vicuna
pip install -r requirements.txt
```

Local python environment is 3.8, torch is 1.13.1, CUDA is 12

NOTE: python3.11 has a known `torchrun` bug, details [here](https://github.com/facebookresearch/llama/issues/86)


### Newest Version=>4bit(qlora)/multi-gpu inference
```
pip install -r requirements_4bit.txt
```
This environment will encounter saving problems when training 8bit, which has not been solved yetÔºàhttps://github.com/TimDettmers/bitsandbytes/issues/324Ôºâ


**Multi-gpu Training**
#### for instruction tuning
**8bit**

```bash
bash scripts/finetune.sh
```

- The parameters to note here are as follows
  - TOT_CUDA, fill in the GPU number to be used, such as `TOT_CUDA="0,1,2,3"`
  - PORT, fill in the corresponding port
  - DATA_PATHÔºåfill in the corresponding data location in the format of json
  - OUTPUT_PATHÔºåfill in the relative path to save the model
  - MODEL_PATHÔºåpath of LLM
  - wandb: This is a training visualization tool that is not turned on by default in the script, and can be turned on by adding "--wandb" to the script


**4bit**
```bash
bash scripts/finetune_4bit.sh
```

#### for conversational instruction tuning

```bash
bash scripts/finetune_chat.sh
```

#### For the case where 8bit cannot be turned on / for commanded trimming of fp16
```bash
bash scripts/finetune_deepspeed.sh
```

- use_deepspeedÔºöset to 1:use deepspeed. Otherwise use fp16

**Single-gpu Training**

```
CUDA_VISIBLE_DEVICES=0 python finetune.py --data_path merge.json --test_size 2000
```

- The test_size cannot be larger than the data size

**inference and use gradio to generate a web page**

```bash
bash scripts/generate.sh
```

- The parameters to note here are as follows

  - BASE_MODELÔºåpath of LLM
  - LORA_PATHÔºåThe checkpoint folder of the lora model
    - It should be noted here that the config loaded by the lora model must be "adapter_config.json" and the model name must be "adapter_model.bin", but it will be automatically saved as "pytorch_model.bin" during training. pytorch_model.bin" during training, while "adapter_config.json" and "adapter_model.bin" will be saved after all training is finished
      - If you load the lora model in the training checkpoint, the code will automatically copy the local "config-sample/adapter_config.json" to the corresponding directory for you and rename the "pytorch_model.bin" to "adapter_model.bin". and rename "pytorch_model.bin" to "adapter_model.bin".
    - It can also be any lora model on the huggingface corresponding to llama 7B, e.g.: `Facico/Chinese-Vicuna-lora-7b-3epoch-belle-and-guanaco`
  - USE_LOCAL, which checks the local model configuration when set to 1
- When using, "max_tokens" is set according to your computer's video memory, and if the generated content generates a lot of duplicate information, you can turn up the "Repetition Penalty".



**Multi-round interaction**

We implemented our own chatbot with streaming output (typewriter-style) using `gradio`, supporting beam search, repetiion penalty settings, the ability to clear history, select different global instruction, etc.

```bash
bash scripts/chat_7B.sh
```

- A simple interactive interface constructed using gradio, which allows you to set the max_memory according to your machine (it will intercept the max_memory part later in the history conversation)

- The prompt used in this script is not quite the same as the one used in generate.sh. The prompt in this script is in the form of a dialogue, as follows

  - ```
    The following is a conversation between an AI assistant called Bot and a human user called User.
    ```

At the same time, for a better interactive experience, 

## Checkpoint Retraining/Incremental Training

Considering the possibility that the program may be disconnected in the middle of  the process, or the need to continue training on vertical domain data,  we have provided corresponding interfaces. 

 The following are the default multi-GPU scripts. Please modify the single-GPU situation according to the above instruction(run directly in Python) 

**Checkpoint Retraining**

```bash
bash scripts/finetune_continue.sh
```

- Set the `lora_checkpoint`

  - If there are optimizer (optimizer.pt), lr policy  (scheduler.pt), and other files in this directory, they will be automatically loaded and retrained from where they were broken 

  - If there are only LORA related models (adapter_model.bin)  and configurations (adapter_config.json) in this directory, they will be loaded and trained from scratch 

- `from_data_beginning`:  The parameter indicates whether to start training from the beginning of the data when loading (default: starting training from the place where the data is disconnected) 

**Incremental Training**

Of course, you can choose to continue training directly from a trained Lora model using the above script (without loading any optimizer parameters)

You can also continue training from our optimizer parameters

```
finetune_others_continue.sh
```

- `from_data_beginning`: This will default to training from the beginning of the data

The logic of this script is mainly to keep the learning rate consistent. If your `max_steps` is smaller than ours, keep `max_steps `consistent with our `max_steps` during training, which is equivalent to putting your data directly behind our disconnected data; if your data set larger than us and will remain directly unchanged.



We currently directly provide checkpoints after 1 epoch and 2 epoch training

- 1epoch: https://github.com/Facico/Chinese-Vicuna/tree/master/lora-Vicuna/checkpoint-5800
- 2epoch: https://github.com/Facico/Chinese-Vicuna/tree/master/lora-Vicuna/checkpoint-11600
- If you use our checkpoint, your program will also continue from the corresponding step

### Specific cases

- Continue-finetune on the vertical corpus of medicalQA , see here [Chinese-Vicuna-medical](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-medical.md)
## **inference on CPU with pure C++**

Details in `tools` [readme](https://github.com/Facico/Chinese-Vicuna/blob/master/tools/readme.md)

## **More Tools**

We also offer:
- ways for faster weight download ( 8MB/s ) : [link](https://github.com/Facico/Chinese-Vicuna/blob/master/tools/download_llama.sh)
- convert tools between the original facebook checkpoint (`consolidated.xx.pth`) and huggingface format (`pytorch_model-000xx-of-000xx.bin`): [link](https://github.com/Facico/Chinese-Vicuna/blob/master/tools/convert_llama.py)
- a quantitative approach that requires less than 4G graphics memory for inference: [link](https://github.com/Facico/Chinese-Vicuna/blob/master/tools/llama_quant.py)

For more details, see [tool readme](https://github.com/Facico/Chinese-Vicuna/tree/master/tools)


# Todo

- [x] belle+guanaco(1.5 epoch, 8000 step)
- [x] belle+guanaco(100%)
- [x] Add more chitchat-like conversational corpus to enhance free conversation
- [x] Add colab training + lora loading interface
- [x] Add the interaction capabilities and typewrite-style output(beam search+streaming output)
- [x] Add llama c++ inference
- [x] Add gptq quantification tools
- [x] Add incremental training
- [x] train on multi-turn instruction dataset
- [x] train more epoch on cleaned instruct-chat combination data
- [x] train on domain-specific datas (medical, legal)
- [ ] add langchain

# Star History
[![Star History Chart](https://api.star-history.com/svg?repos=Facico/Chinese-Vicuna&type=Date)](https://star-history.com/#Facico/Chinese-Vicuna&Date)

# Citation

If you find this project useful in your research, please consider citing:

```
@misc{fan2025chinesevicunachineseinstructionfollowingllamabased,
      title={Chinese-Vicuna: A Chinese Instruction-following Llama-based Model}, 
      author={Chenghao Fan and Zhenyi Lu and Jie Tian},
      year={2025},
      eprint={2504.12737},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.12737}, 
}
```
